{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import random\n",
    "import os\n",
    "from lib.transfer_functions import transfer_function\n",
    "from lib.additive_model import add_mirna_combs, max_mirna_combs, add_mirna_expression, max_mirna_expression\n",
    "\n",
    "cell_lines_main = [\"HEK293T\", \"HeLa\", \"SKNSH\", \"MCF7\", \"HUH-7\", \"A549\"]\n",
    "cell_lines_other = [\"HaCaT\", \"JEG-3\", \"Tera-1\", \"PC-3\"]\n",
    "cell_lines_measured = [\"HEK293T\", \"HeLa\", \"SKNSH\", \"MCF7\"]\n",
    "cell_lines = cell_lines_main + cell_lines_other\n",
    "\n",
    "plot_folder = \"../plots/7_miRNA_combinations/\"\n",
    "# Create folder for plots if it does not exist\n",
    "if not os.path.exists(plot_folder):\n",
    "    os.makedirs(plot_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here, we pick combinations of different full and mutated targets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.1 - Full target combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set miRNA expression buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load microRNA data\n",
    "mirna_data_filter = pd.read_csv(\"../input_data/miRNA_expression_data/1_output/1.10_alles_quantile_crosstalk_filter.csv\", index_col=0)\n",
    "mirna_data_filter = mirna_data_filter.loc[:, cell_lines]\n",
    "\n",
    "# get mirbase data\n",
    "mirbase_df = pd.read_csv('../input_data/mirbase_with_families_and_targets.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out mirnas that contain unwanted sequence motifs\n",
    "# restriction sites for BsaI\n",
    "restriction_sites = [\"GAGACC\", \"GGTCTC\"]\n",
    "polyA_signals = [\"AATAAA\", \"ATTAAA\", \"AGTAAA\", \"TATAAA\", \"ACTAAA\"]\n",
    "filter_motifs = restriction_sites + polyA_signals\n",
    "\n",
    "# check which miRNAs contain restriction sites in their target sequence\n",
    "forbidden = mirbase_df[mirbase_df[\"target\"].str.contains(\"|\".join(filter_motifs)) == True].index\n",
    "mirna_data_filter = mirna_data_filter[mirna_data_filter.index.isin(forbidden) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stability = (10**mirna_data_filter).apply(transfer_function)\n",
    "mirna_data = mirna_data_filter.copy()\n",
    "mirna_data[\"mean\"] = mirna_data.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets = [(2.5,3),(3,3.5),(3.5,6)]\n",
    "\n",
    "data_buckets = []\n",
    "for bucket in buckets:\n",
    "    data_buckets.append(mirna_data[(mirna_data[\"mean\"] >= bucket[0]) & (mirna_data[\"mean\"] < bucket[1])])\n",
    "\n",
    "data_bucket_mirnas = []\n",
    "for bucket in data_buckets:\n",
    "    data_bucket_mirnas.append(list(bucket.index.values))\n",
    "\n",
    "# print the number of miRNAs in each bucket\n",
    "for bucket in data_buckets:\n",
    "    print(len(bucket))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create construucts with 2 miRNA targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sorted_mirnas(row, n):\n",
    "    return tuple(sorted([row[f\"miRNA{i}\"] for i in range(1,n+1)]))\n",
    "\n",
    "def get_random_mirna():\n",
    "    # pick a random bucket\n",
    "    rand_bucket = random.choice(data_bucket_mirnas)\n",
    "    # pick a random mirnas from the bucket\n",
    "    rand_mirna = random.choice(rand_bucket)\n",
    "    return rand_mirna\n",
    "\n",
    "def get_random_mirna_comb(n_mirnas, n_combinations):\n",
    "    mirna_combs = []\n",
    "    for i in range(n_combinations):\n",
    "        mirna_comb = []\n",
    "        for j in range(n_mirnas):\n",
    "            mirna_comb.append(get_random_mirna())\n",
    "        mirna_combs.append(tuple(sorted(mirna_comb)))\n",
    "    return mirna_combs\n",
    "\n",
    "def get_random_mirna_df(n_mirnas, n_combinations, index_start=0, label_start=0):\n",
    "    rand_comb = pd.DataFrame(get_random_mirna_comb(n_mirnas, n_combinations), columns=[f\"miRNA{i+1}\" for i in range(n_mirnas)])\n",
    "    rand_comb[\"category\"] = \"random\"\n",
    "    rand_comb[\"sorted_mirnas\"] = rand_comb.apply(lambda row: get_sorted_mirnas(row, n_mirnas), axis=1)\n",
    "    columns = [f\"miRNA{i+1}\" for i in range(n_mirnas)] + [\"category\", \"sorted_mirnas\"]\n",
    "    rand_comb = rand_comb[columns]\n",
    "    rand_comb.index =[f\"{label_start}_miRNA_full_combination_probe_{index_start+i+1}\" for i in range(n_combinations)]\n",
    "    return rand_comb\n",
    "\n",
    "def save_flattened_df(AND_df, n_mirnas, label_start, mut=\"full\"):\n",
    "    AND_df_flat = pd.concat(AND_df, axis=0)\n",
    "    # are there duplicates?\n",
    "    print(AND_df_flat[AND_df_flat.duplicated(subset=\"sorted_mirnas\")])\n",
    "    # if so, keep only the first\n",
    "    AND_df_flat = AND_df_flat[~AND_df_flat.duplicated(subset=\"sorted_mirnas\")]\n",
    "    # reindex\n",
    "    AND_df_flat.index = [f\"{label_start}_miRNA_{mut}_combination_probe_x{n_mirnas}_{i+1}\" for i in range(len(AND_df_flat))]\n",
    "    # save to csv\n",
    "    AND_df_flat.to_csv(f\"../designs/{label_start}_miRNA_{mut}_combination_probe_x{n_mirnas}.csv\")\n",
    "    # return the df\n",
    "    return AND_df_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_combinations = [30, 30, 20]\n",
    "\n",
    "# get combinations from the same category\n",
    "AND2 = []\n",
    "categories = [\"low\", \"mid\", \"high\"]\n",
    "for i, mirna_bucket in enumerate(data_bucket_mirnas):\n",
    "    new_mirnas = random.sample(list(itertools.combinations(mirna_bucket, 2)), no_combinations[i])\n",
    "    df = pd.DataFrame(new_mirnas, columns=[\"miRNA1\", \"miRNA2\"])\n",
    "    df[\"category\"] = categories[i]\n",
    "    df[\"sorted_mirnas\"] = df.apply(lambda row: get_sorted_mirnas(row, 2), axis=1)\n",
    "    df = df[[\"miRNA1\", \"miRNA2\", \"category\", \"sorted_mirnas\"]]\n",
    "    AND2.append(df)\n",
    "\n",
    "no_rand_comb = 20\n",
    "index_start = sum(no_combinations)\n",
    "label_start = 11\n",
    "rand_comb_2 = get_random_mirna_df(2, no_rand_comb, index_start, label_start)\n",
    "AND2.append(rand_comb_2)\n",
    "\n",
    "AND2_flat = save_flattened_df(AND2, 2, label_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create combinations of 3 to 6 targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mirna_buckets(n_mirnas, basis_df, buckets):\n",
    "    result_df = []\n",
    "    for i, bucket in enumerate(buckets):\n",
    "        df = basis_df[i].copy()\n",
    "        df[f\"miRNA{n_mirnas}\"] = [random.choice(bucket) for i in range(len(df))]\n",
    "        df[\"category\"] = categories[i]\n",
    "        df[\"sorted_mirnas\"] = df.apply(lambda row: get_sorted_mirnas(row, n_mirnas), axis=1)\n",
    "        columns = [f\"miRNA{i+1}\" for i in range(n_mirnas)] + [\"category\", \"sorted_mirnas\"]\n",
    "        df = df[columns]\n",
    "        result_df.append(df)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_start = 12\n",
    "n_mirnas = 3\n",
    "AND3 = get_mirna_buckets(n_mirnas, AND2, data_bucket_mirnas)\n",
    "rand_comb_3 = get_random_mirna_df(n_mirnas, no_rand_comb, index_start, label_start)\n",
    "AND3.append(rand_comb_3)\n",
    "AND3_flat = save_flattened_df(AND3, n_mirnas, label_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_start = 13\n",
    "n_mirnas = 4\n",
    "AND4 = get_mirna_buckets(n_mirnas, AND3, data_bucket_mirnas)\n",
    "rand_comb_4 = get_random_mirna_df(n_mirnas, no_rand_comb, index_start, label_start)\n",
    "AND4.append(rand_comb_4)\n",
    "AND4_flat = save_flattened_df(AND4, n_mirnas, label_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_start = 14\n",
    "n_mirnas = 5\n",
    "AND5 = get_mirna_buckets(n_mirnas, AND4, data_bucket_mirnas)\n",
    "rand_comb_5 = get_random_mirna_df(n_mirnas, no_rand_comb, index_start, label_start)\n",
    "AND5.append(rand_comb_5)\n",
    "AND5_flat = save_flattened_df(AND5, n_mirnas, label_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_start = 15\n",
    "n_mirnas = 6\n",
    "AND6 = get_mirna_buckets(n_mirnas, AND5, data_bucket_mirnas)\n",
    "rand_comb_6 = get_random_mirna_df(n_mirnas, no_rand_comb, index_start, label_start)\n",
    "AND6.append(rand_comb_6)\n",
    "AND6_flat = save_flattened_df(AND6, n_mirnas, label_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add some of the previous designs (never ended up doing anything with these)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_designs = pd.read_csv(\"../input_data/measurements_lib1/7_full_AND5_context1.csv\", index_col=0)\n",
    "previous_designs = previous_designs.iloc[::2,:]\n",
    "previous_designs = previous_designs[[\"miRNA1\", \"miRNA2\", \"miRNA3\", \"miRNA4\", \"miRNA5\"]]\n",
    "previous_designs[\"sorted_mirnas\"] = previous_designs.apply(lambda row: get_sorted_mirnas(row, 5), axis=1)\n",
    "previous_designs[\"category\"] = \"previous\"\n",
    "previous_designs.index = [f\"16_miRNA_previous_\" + \"_\".join(previous_designs.index[i].split(\"_\")[2:-1]) for i in range(len(previous_designs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_designs.to_csv(\"../designs/16_miRNA_previous_AND5.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore expected stability patterns\n",
    "Here, we want to make sure that we can distinguish the effect of multiple miRNAs from the strongest miRNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_df = AND5_flat\n",
    "\n",
    "AND_expression = add_mirna_expression(10**mirna_data_filter, used_df)\n",
    "AND_max = max_mirna_expression(10**mirna_data_filter, used_df)\n",
    "\n",
    "AND_knockdown = AND_expression.apply(transfer_function).astype(float)\n",
    "AND_max_knockdown = AND_max.apply(transfer_function).astype(float)\n",
    "\n",
    "# ratio add vs max\n",
    "AND_expression_ratio = AND_expression.div(AND_max)\n",
    "\n",
    "for cell_line in cell_lines:\n",
    "    plt.figure(figsize=(3,2.5))\n",
    "    plt.plot(np.log10(AND_knockdown.loc[:,cell_line]), np.log10(AND_knockdown.loc[:,cell_line]), color=\"black\")\n",
    "    plt.scatter(np.log10(AND_knockdown.loc[:,cell_line]), np.log10(AND_max_knockdown.loc[:,cell_line]), s=8,\n",
    "                edgecolors='none', color=\"tab:blue\")\n",
    "    plt.xlabel(\"Additive model\")\n",
    "    plt.ylabel(\"Max model\")\n",
    "    plt.title(cell_line)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plot_folder, f\"fill_{cell_line}_AND_expression_vs_knockdown.png\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.2 - Mutated target combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read mutation data\n",
    "mutation_df = pd.read_csv(\"../designs/5_miRNA_single_mut.csv\", index_col=0)\n",
    "\n",
    "chosen_mirnas = list(mutation_df[\"orig_mi\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for unwanted motifs\n",
    "print(mutation_df[mutation_df[\"target\"].str.contains(\"|\".join(filter_motifs)) == True].index)\n",
    "mutation_df = mutation_df[mutation_df[\"target\"].str.contains(\"|\".join(filter_motifs)) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heuristically divide mutations according to their expected impact on miRNA function\n",
    "# (The warning are irrelevant for filtering.)\n",
    "# --------------------------------------\n",
    "# get single mutations\n",
    "single_mutations = mutation_df[mutation_df.index.str.contains(\"5.1_\")]\n",
    "weak_single = single_mutations[single_mutations.index.to_series().str.contains(r'_(mut|wob)(9|1[0-9]|20)\\b')]\n",
    "medium_single = single_mutations[single_mutations.index.to_series().str.contains(r'_(mut)(1|2|3|4|5|6|7|8)\\b')]\n",
    "\n",
    "# --------------------------------------\n",
    "# get double mutations\n",
    "weak_double = mutation_df[mutation_df.index.str.contains(r'5\\.(7|8|9|10)_miRNA')]\n",
    "medium_double = mutation_df[mutation_df.index.str.contains(r'5\\.6_miRNA')]\n",
    "\n",
    "# --------------------------------------\n",
    "# get triple mutations\n",
    "medium_triple = mutation_df[mutation_df.index.str.contains(r'5\\.(1[4-7])_miRNA')]\n",
    "strong_triple = mutation_df[mutation_df.index.str.contains(r'5\\.(12|13)_miRNA')]\n",
    "\n",
    "# --------------------------------------\n",
    "# get quadruple mutations\n",
    "medium_quadruple = mutation_df[mutation_df.index.str.contains(r'5\\.(2[1-4])_miRNA')]\n",
    "strong_quadruple = mutation_df[mutation_df.index.str.contains(r'5\\.(18|19|20)_miRNA')]\n",
    "\n",
    "# --------------------------------------\n",
    "weak_mutations = pd.concat([weak_single, weak_double], axis=0)\n",
    "medium_mutations = pd.concat([medium_single, medium_double, medium_triple, medium_quadruple], axis=0)\n",
    "strong_mutations = pd.concat([strong_triple, strong_quadruple], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the mutation buckets\n",
    "# add non-mutated miRNAs to the first bucket\n",
    "mid_mirnas = data_bucket_mirnas[1]\n",
    "mutation_buckets = [mid_mirnas*10+weak_mutations.index.to_list(), weak_mutations.index.to_list(),\n",
    "                    medium_mutations.index.to_list(), strong_mutations.index.to_list()]\n",
    "\n",
    "no_combinations = [20, 35, 35, 25]\n",
    "label_start = 17\n",
    "\n",
    "# get combinations from the same category\n",
    "AND2_mut = []\n",
    "categories = [\"mixed\", \"weak\", \"medium\", \"strong\"]\n",
    "for i, mutation_bucket in enumerate(mutation_buckets):\n",
    "    new_mirnas = random.sample(list(itertools.combinations(mutation_bucket, 2)), no_combinations[i])\n",
    "    df = pd.DataFrame(new_mirnas, columns=[\"miRNA1\", \"miRNA2\"])\n",
    "    df[\"category\"] = categories[i]\n",
    "    df[\"sorted_mirnas\"] = df.apply(lambda row: get_sorted_mirnas(row, 2), axis=1)\n",
    "    df = df[[\"miRNA1\", \"miRNA2\", \"category\", \"sorted_mirnas\"]]\n",
    "    AND2_mut.append(df)\n",
    "\n",
    "AND2_mut_flat = save_flattened_df(AND2_mut, 2, label_start, mut=\"mut\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_start = 18\n",
    "n_mirnas = 3\n",
    "AND3_mut = get_mirna_buckets(n_mirnas, AND2_mut, mutation_buckets)\n",
    "AND3_mut_flat = save_flattened_df(AND3_mut, n_mirnas, label_start, mut=\"mut\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_start = 19\n",
    "n_mirnas = 4\n",
    "AND4_mut = get_mirna_buckets(n_mirnas, AND3_mut, mutation_buckets)\n",
    "AND4_mut_flat = save_flattened_df(AND4_mut, n_mirnas, label_start, mut=\"mut\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_start = 20\n",
    "n_mirnas = 5\n",
    "AND5_mut = get_mirna_buckets(n_mirnas, AND4_mut, mutation_buckets)\n",
    "AND5_mut_flat = save_flattened_df(AND5_mut, n_mirnas, label_start, mut=\"mut\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_start = 21\n",
    "n_mirnas = 6\n",
    "AND6_mut = get_mirna_buckets(n_mirnas, AND5_mut, mutation_buckets)\n",
    "AND6_mut_flat = save_flattened_df(AND6_mut, n_mirnas, label_start, mut=\"mut\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
