{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import itertools\n",
    "import random\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "from lib.context_insertion import distance_to_start_codon, determine_generic_ins_positions, insert_miRNA_sites\n",
    "\n",
    "cell_lines_main = [\"HEK293T\", \"HeLa\", \"SKNSH\", \"MCF7\", \"HUH-7\", \"A549\"]\n",
    "cell_lines_other = [\"HaCaT\", \"JEG-3\", \"Tera-1\", \"PC-3\"]\n",
    "cell_lines_measured = [\"HEK293T\", \"HeLa\", \"SKNSH\", \"MCF7\"]\n",
    "cell_lines = cell_lines_main + cell_lines_other\n",
    "\n",
    "output_folder = \"../designs/inserted/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the target sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mirbase_df = pd.read_csv(\"../data/miRNA_data/mirbase_with_targets.csv\", index_col=0)\n",
    "mirbase_df = mirbase_df[[\"target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutation_df = pd.read_csv(\"../designs/5_miRNA_single_mut.csv\", index_col=0)\n",
    "mutation_df = mutation_df[[\"target\"]]\n",
    "# replace Us by Ts in the mutation df\n",
    "mutation_df[\"target\"] = mutation_df[\"target\"].apply(lambda x: x.replace(\"U\", \"T\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df = pd.concat([mirbase_df, mutation_df])\n",
    "\n",
    "# get the position of the first ATG\n",
    "target_df[\"ATG_pos\"] = target_df[\"target\"].apply(lambda x: [match.start() for match in re.finditer('ATG', x)])\n",
    "# get the position of the first ATG modulo 3\n",
    "target_df[\"ATG_pos_mod3\"] = target_df[\"ATG_pos\"].apply(lambda x: [entry%3 for entry in x])\n",
    "# fill the empty lists with 0\n",
    "target_df['ATG_pos_mod3'] = target_df['ATG_pos_mod3'].apply(lambda x: x if x else [0])\n",
    "# get the ATG count\n",
    "target_df[\"ATG_count\"] = target_df[\"target\"].apply(lambda x: x.count(\"ATG\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert targets into the context sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_target_sites(df, n_mirnas, target_df):\n",
    "    \"\"\"This code adds target sites to the dataframe df. The target sites are taken from the target_df dataframe.\"\"\"\n",
    "    for i in range(n_mirnas):\n",
    "        df.loc[:,f\"target{i+1}\"] = df[f\"miRNA{i+1}\"].map(target_df[\"target\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAAGAGCAGAAGCAGCAGCATCTCTGTACATTTTGGAGCCAAGGGTTCAGAGACTCAGGGCCCCAGCACTTAAGCAGTGGACACCAGGAGTCCCTGGTAATCAGTACTGTGTACAGAATTCTGCTACCTCACTACAAGCAGAAGGAAACATTGAACTCAGAGCC\n",
      "164\n"
     ]
    }
   ],
   "source": [
    "# load the context data\n",
    "with open(\"../designs/context/universal_lib2_context.txt\", \"r\") as f:\n",
    "    context_lib2 = f.readline().strip()\n",
    "    print(context_lib2)\n",
    "    print(len(context_lib2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1_mi', '2_mi', '3_mi', '5_mi', '6_mi', '7_mi', '8_mi', '9_mi', '10_mi', '11_mi', '12_mi', '13_mi', '14_mi', '15_mi', '16_mi', '17_mi', '18_mi', '19_mi', '20_mi', '21_mi', '22_mi', '23_mi', '24_mi', '25_mi', '26_mi', '27_mi', '28_mi', '29_mi', '30_mi', '31_mi', '32_mi', '33_mi', '34_mi', '35_mi', '36_mi', '37_mi', '38_mi', '39_mi', '40_mi', '41_mi', '42_mi', '43_mi', '44_mi', '45_mi', '46_mi', '47_mi', '48_mi', '49_mi']\n"
     ]
    }
   ],
   "source": [
    "# some of the designs (0_lib2_controls and 4_miRNA_full_single_context_controls) have already been generated. We need to skip them.\n",
    "prefixes = [f\"{i}_mi\" for i in range(1, 50) if i != 4]\n",
    "print(prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10_miRNA_full_repeat_x6.csv', '11_miRNA_full_combination_probe_x2.csv', '12_miRNA_full_combination_probe_x3.csv', '13_miRNA_full_combination_probe_x4.csv', '14_miRNA_full_combination_probe_x5.csv', '15_miRNA_full_combination_probe_x6.csv', '16_miRNA_previous_AND5.csv', '17_miRNA_mut_combination_probe_x2.csv', '18_miRNA_mut_combination_probe_x3.csv', '19_miRNA_mut_combination_probe_x4.csv', '1_mirna_full_single_high_conf.csv', '20_miRNA_mut_combination_probe_x5.csv', '21_miRNA_mut_combination_probe_x6.csv', '22_miRNA_full_combination_shuffle_x5.csv', '23_miRNA_mut_combination_shuffle_x5.csv', '24_miRNA_full_subset_quality_AND4.csv', '25_miRNA_full_subset_quality_AND5.csv', '26_miRNA_full_subset_quality_AND6.csv', '27_miRNA_full_quality_AND4.csv', '28_miRNA_full_quality_AND5.csv', '29_miRNA_full_quality_AND6.csv', '2_mirna_full_single_low_conf_mirgenedb.csv', '30_miRNA_AND4_subset_mse_designs.csv', '31_miRNA_AND5_subset_mse_designs.csv', '32_miRNA_AND6_subset_mse_designs.csv', '33_miRNA_AND4_all_mse_designs.csv', '34_miRNA_AND5_all_mse_designs.csv', '35_miRNA_AND6_all_mse_designs.csv', '36_miRNA_mut_repeat_x2.csv', '37_miRNA_mut_repeat_x3.csv', '38_miRNA_mut_repeat_x4.csv', '39_miRNA_mut_repeat_x5.csv', '3_mirna_full_single_low_conf_not_mirgenedb.csv', '40_miRNA_mut_repeat_x6.csv', '5_miRNA_single_mut.csv', '6_miRNA_full_repeat_x2.csv', '7_miRNA_full_repeat_x3.csv', '8_miRNA_full_repeat_x4.csv', '9_miRNA_full_repeat_x5.csv']\n"
     ]
    }
   ],
   "source": [
    "# get the names of all csv files in the design folder using glob\n",
    "csv_files = os.listdir(\"../designs/\")\n",
    "# filter to those that contain the prefixes\n",
    "csv_files = [file for file in csv_files if any([prefix in file for prefix in prefixes])]\n",
    "print(csv_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10_miRNA_full_repeat_x6.csv 100\n",
      "11_miRNA_full_combination_probe_x2.csv 100\n",
      "12_miRNA_full_combination_probe_x3.csv 100\n",
      "13_miRNA_full_combination_probe_x4.csv 100\n",
      "14_miRNA_full_combination_probe_x5.csv 100\n",
      "15_miRNA_full_combination_probe_x6.csv 100\n",
      "16_miRNA_previous_AND5.csv 20\n",
      "17_miRNA_mut_combination_probe_x2.csv 115\n",
      "18_miRNA_mut_combination_probe_x3.csv 115\n",
      "19_miRNA_mut_combination_probe_x4.csv 115\n",
      "1_mirna_full_single_high_conf.csv 861\n",
      "20_miRNA_mut_combination_probe_x5.csv 115\n",
      "21_miRNA_mut_combination_probe_x6.csv 115\n",
      "22_miRNA_full_combination_shuffle_x5.csv 450\n",
      "23_miRNA_mut_combination_shuffle_x5.csv 600\n",
      "24_miRNA_full_subset_quality_AND4.csv 54\n",
      "25_miRNA_full_subset_quality_AND5.csv 54\n",
      "26_miRNA_full_subset_quality_AND6.csv 54\n",
      "27_miRNA_full_quality_AND4.csv 90\n",
      "28_miRNA_full_quality_AND5.csv 90\n",
      "29_miRNA_full_quality_AND6.csv 90\n",
      "2_mirna_full_single_low_conf_mirgenedb.csv 166\n",
      "30_miRNA_AND4_subset_mse_designs.csv 540\n",
      "31_miRNA_AND5_subset_mse_designs.csv 540\n",
      "32_miRNA_AND6_subset_mse_designs.csv 540\n",
      "33_miRNA_AND4_all_mse_designs.csv 572\n",
      "34_miRNA_AND5_all_mse_designs.csv 572\n",
      "35_miRNA_AND6_all_mse_designs.csv 572\n",
      "36_miRNA_mut_repeat_x2.csv 110\n",
      "37_miRNA_mut_repeat_x3.csv 110\n",
      "38_miRNA_mut_repeat_x4.csv 110\n",
      "39_miRNA_mut_repeat_x5.csv 110\n",
      "3_mirna_full_single_low_conf_not_mirgenedb.csv 293\n",
      "40_miRNA_mut_repeat_x6.csv 110\n",
      "5_miRNA_single_mut.csv 1092\n",
      "6_miRNA_full_repeat_x2.csv 100\n",
      "7_miRNA_full_repeat_x3.csv 100\n",
      "8_miRNA_full_repeat_x4.csv 100\n",
      "9_miRNA_full_repeat_x5.csv 100\n"
     ]
    }
   ],
   "source": [
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(f\"../designs/{csv_file}\", index_col=0)\n",
    "    print(csv_file, len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_region_len = len(context_lib2)\n",
    "three_p_seq_len = 61\n",
    "target_len = 21\n",
    "dist_between = 6\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(f\"../designs/{csv_file}\", index_col=0)\n",
    "    mirna_columns = [col for col in df.columns if \"miRNA\" in col]\n",
    "    n_mirnas = len(mirna_columns)\n",
    "    df = add_target_sites(df, n_mirnas, target_df)\n",
    "    df.loc[:, \"context\"] = \"context_lib2\"\n",
    "\n",
    "    # get the insertion position\n",
    "    insertion_positions = determine_generic_ins_positions(\n",
    "                                                    var_region_len=var_region_len,\n",
    "                                                    three_p_seq_len=three_p_seq_len,\n",
    "                                                    target_len=target_len,\n",
    "                                                    dist_between=dist_between,\n",
    "                                                    no_of_inserts=n_mirnas)\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        mirnas = [row[col] for col in mirna_columns]\n",
    "        df.loc[index, \"seq\"] = insert_miRNA_sites(context_lib2, insertion_positions, target_df, mirnas)\n",
    "\n",
    "    df.to_csv(f\"{output_folder}{csv_file.split('.')[0]}_inserted.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the final sequences by adding the adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    9375.0\n",
      "mean      164.0\n",
      "std         0.0\n",
      "min       164.0\n",
      "25%       164.0\n",
      "50%       164.0\n",
      "75%       164.0\n",
      "max       164.0\n",
      "Name: seq, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# get a list of all files in the output folder\n",
    "files = os.listdir(output_folder)\n",
    "\n",
    "# read each file into a dataframe and append to a list\n",
    "dfs = []\n",
    "for file in files:\n",
    "    df = pd.read_csv(os.path.join(output_folder, file), index_col=0)\n",
    "    # only keep the sequence\n",
    "    df = df[[\"seq\"]]\n",
    "    dfs.append(df)\n",
    "\n",
    "# concatenate all dataframes in the list\n",
    "all_designs = pd.concat(dfs, axis=0)\n",
    "\n",
    "# print statistics on the length of the sequences, i.e., the length of each entry in the seq column\n",
    "print(all_designs[\"seq\"].str.len().describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the context and control sequences\n",
    "df = pd.read_csv(f\"../designs/0_lib2_controls.csv\", index_col=0)\n",
    "df = df[[\"seq\"]]\n",
    "all_designs = pd.concat([all_designs, df], axis=0)\n",
    "\n",
    "df = pd.read_csv(f\"../designs/4_miRNA_full_single_context_controls.csv\", index_col=0)\n",
    "df = df[[\"seq\"]]\n",
    "all_designs = pd.concat([all_designs, df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    10027.0\n",
      "mean       164.0\n",
      "std          0.0\n",
      "min        164.0\n",
      "25%        164.0\n",
      "50%        164.0\n",
      "75%        164.0\n",
      "max        164.0\n",
      "Name: seq, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# print statistics on the length of the sequences, i.e., the length of each entry in the seq column\n",
    "print(all_designs[\"seq\"].str.len().describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    10007.0\n",
      "mean       164.0\n",
      "std          0.0\n",
      "min        164.0\n",
      "25%        164.0\n",
      "50%        164.0\n",
      "75%        164.0\n",
      "max        164.0\n",
      "Name: seq, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# are there any duplicate entries?\n",
    "# get all duplicated sequences, and make sure to group them by the sequence\n",
    "duplicated = all_designs[all_designs.duplicated(subset=\"seq\", keep=False)].sort_values(\"seq\")\n",
    "\n",
    "# Group and list duplicates\n",
    "grouped_duplicates = duplicated.groupby(\"seq\").apply(lambda x: x.index.tolist())\n",
    "grouped_duplicates.to_excel(\"../designs/additional_info/duplicated_sequences.xlsx\")\n",
    "\n",
    "# Drop duplicates\n",
    "all_designs = all_designs.drop_duplicates(subset=\"seq\", keep=\"first\")\n",
    "\n",
    "# print the new length\n",
    "print(all_designs[\"seq\"].str.len().describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add the adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_handle = \"ACGACGCTCTTCCGATCT\"\n",
    "right_handle = \"CTCTGGATTTGCAACCGA\"\n",
    "all_designs[\"seq\"] = left_handle + all_designs[\"seq\"] + right_handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    10007.0\n",
      "mean       200.0\n",
      "std          0.0\n",
      "min        200.0\n",
      "25%        200.0\n",
      "50%        200.0\n",
      "75%        200.0\n",
      "max        200.0\n",
      "Name: seq, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(all_designs[\"seq\"].str.len().describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the generated sequences\n",
    "\n",
    "I should check for\n",
    "- restriction sites (BsaI: GAGACC, GGTCTC) [ended up using Gibson cloning]\n",
    "- start codons (ATG) and their distance to the start site\n",
    "- polyA signals (AATAAA|ATTAAA|AGTAAA|TATAAA|ACTAAA)\n",
    "- homopolymers (AAAA|TTTT|CCCC|GGGG)\n",
    "\n",
    "I should also look at\n",
    "- GC content\n",
    "- length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "# look at restriction sites\n",
    "restriction_sites = [\"GAGACC\", \"GGTCTC\"]\n",
    "# print how many of the sequences contain the restriction sites\n",
    "print(all_designs[\"seq\"].str.contains(\"|\".join(restriction_sites)).sum())\n",
    "all_designs[all_designs[\"seq\"].str.contains(\"|\".join(restriction_sites)) == True].to_excel(\"../designs/additional_info/restriction_sites.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "Index(['1_mirna_full_single_high_conf_94', '1_mirna_full_single_high_conf_307',\n",
      "       '1_mirna_full_single_high_conf_638',\n",
      "       '1_mirna_full_single_high_conf_639',\n",
      "       '2_mirna_full_single_low_conf_mirgenedb_165',\n",
      "       '5.14_miRNA_let-7a-5p_smut_swob_omut11.15.19_owob'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# look at polyA signals\n",
    "polyA_signals = [\"AATAAA\", \"ATTAAA\", \"AGTAAA\", \"TATAAA\", \"ACTAAA\"]\n",
    "# print how many of the sequences contain the polyA signals\n",
    "print(all_designs[\"seq\"].str.contains(\"|\".join(polyA_signals)).sum())\n",
    "all_designs[all_designs[\"seq\"].str.contains(\"|\".join(polyA_signals)) == True].to_excel(\"../designs/additional_info/polyA_signals.xlsx\")\n",
    "\n",
    "# delete the sequences that contain \"AATAAA\" or \"ATTAAA\"\n",
    "print(all_designs[all_designs[\"seq\"].str.contains(\"AATAAA\") == True].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the sequences that contain \"AATAAA\"\n",
    "all_designs = all_designs[all_designs[\"seq\"].str.contains(\"AATAAA\") == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10001\n"
     ]
    }
   ],
   "source": [
    "print(len(all_designs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6231\n",
      "0    6225\n",
      "2    3772\n",
      "1       4\n",
      "Name: seq, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# look at start codons\n",
    "start_codons = [\"ATG\"]\n",
    "# print how many of the sequences contain the start codons\n",
    "print(all_designs[\"seq\"].str.contains(\"|\".join(start_codons)).sum())\n",
    "# print the statistics of their position in the sequence modulo 3\n",
    "print(all_designs[\"seq\"].str.find(\"ATG\").mod(3).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    10001.0\n",
      "mean       200.0\n",
      "std          0.0\n",
      "min        200.0\n",
      "25%        200.0\n",
      "50%        200.0\n",
      "75%        200.0\n",
      "max        200.0\n",
      "Name: seq, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# how many sequences do I have?\n",
    "print(all_designs[\"seq\"].str.len().describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    9999.0\n",
      "mean      200.0\n",
      "std         0.0\n",
      "min       200.0\n",
      "25%       200.0\n",
      "50%       200.0\n",
      "75%       200.0\n",
      "max       200.0\n",
      "Name: seq, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# print statistics on the length of the sequences, i.e., the length of each entry in the seq column\n",
    "print(all_designs[\"seq\"].str.len().describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prefix present: True    9999\n",
      "Name: seq, dtype: int64\n",
      "suffix present: True    9999\n",
      "Name: seq, dtype: int64\n",
      "prefix position: 0    9999\n",
      "Name: seq, dtype: int64\n",
      "suffix position: 182    9999\n",
      "Name: seq, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# for each oligoseq, check if the prefix and suffix are present\n",
    "print(\"prefix present:\", all_designs['seq'].str.contains(left_handle).value_counts())\n",
    "print(\"suffix present:\", all_designs['seq'].str.contains(right_handle).value_counts())\n",
    "\n",
    "# get value counts of the positions of the prefix and suffix\n",
    "print(\"prefix position:\", all_designs['seq'].apply(lambda x: x.find(left_handle)).value_counts())\n",
    "print(\"suffix position:\", all_designs['seq'].apply(lambda x: x.find(right_handle)).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# check if all indices are unique\n",
    "print(all_designs.index.is_unique)\n",
    "# check if all oligoseqs are unique\n",
    "print(all_designs['seq'].is_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write designs to a csv file\n",
    "all_designs.to_csv(\"../designs/all_designs/all_designs.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
