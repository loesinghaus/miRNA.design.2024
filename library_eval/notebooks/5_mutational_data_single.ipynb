{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import itertools\n",
    "import os\n",
    "import pickle\n",
    "from library2_utils.color_scheme import cell_line_colors, cell_line_symbols\n",
    "from library2_utils.transfer_functions import transfer_function\n",
    "from typing import Union\n",
    "import ast\n",
    "\n",
    "# set the font size\n",
    "plt.rcParams.update({'font.size': 7})\n",
    "# set Helvetica globally\n",
    "plt.rcParams['font.family'] = 'Helvetica'\n",
    "\n",
    "# suppress setting with copy warning\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "cell_lines_measured = [\"HEK293T\", \"HeLa\", \"SKNSH\", \"MCF7\", \"HUH7\", \"A549\", \"HaCaT\", \"JEG3\", \"Tera1\", \"PC3\"]\n",
    "base_plot_folder = f\"../plots/5_mutational_data_single/\"\n",
    "\n",
    "# create it if it does not exist\n",
    "if not os.path.exists(base_plot_folder):\n",
    "    os.makedirs(base_plot_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_input = \"../measured_data/2_normalized_log10\"\n",
    "\n",
    "# get the name of all files in \"reference\" folder\n",
    "reference_files = os.listdir(data_dir_input)\n",
    "\n",
    "# read them into a dictionary\n",
    "reference_dict = {}\n",
    "for reference_file in reference_files:\n",
    "    if reference_file.endswith(\".csv\"):\n",
    "        reference_dict[reference_file.split('.')[0]] = pd.read_csv(os.path.join(data_dir_input, reference_file), index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1 - Get the relevant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### What is the organization of the data?\n",
    "5.0 will be added as non-mutated control data [from 1_]\n",
    "5.1 contains single mutations along the microRNA sequence\n",
    "5.2 contains single wobble mutations along the microRNA sequence (where possible)\n",
    "5.3 contains A mutations inserted at position 1 where possible\n",
    "5.8 contains double mutations (amongst other things)\n",
    "\n",
    "The entire rest contains various mutation patterns with multiple mutations or wobbles.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_data = reference_dict[\"1_mirna_full_single_high_conf\"].copy()\n",
    "mut_data = reference_dict[\"5_miRNA_single_mut\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mut_mirs = mut_data[\"orig_mi\"].unique()\n",
    "single_data = single_data[single_data[\"miRNA1\"].isin(mut_mirs)]\n",
    "\n",
    "# drop predicted_ columns\n",
    "single_data = single_data.drop([col for col in single_data.columns if \"predicted_\" in col], axis=1)\n",
    "single_data[\"orig_mi\"] = single_data[\"miRNA1\"]\n",
    "\n",
    "# append the two dataframes\n",
    "mut_data = pd.concat([single_data, mut_data], axis=0)\n",
    "\n",
    "# remove _3UTR in the column names\n",
    "mut_data.columns = [col.replace(\"_3UTR\", \"\") for col in mut_data.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alter the index for the added non-mutated data to 5.0_miRNA_...\n",
    "new_index = []\n",
    "for idx, value in mut_data.iterrows():\n",
    "    if idx.startswith('1_mirna_full_single'):\n",
    "        # This splits the miRNA name and takes everything after 'hsa'\n",
    "        mirna_name = value[0].split('-')[1:]  \n",
    "        \n",
    "        # Join it back together\n",
    "        mirna_name = '-'.join(mirna_name)  \n",
    "        \n",
    "        # Construct the new index\n",
    "        new_idx = f'5.0_miRNA_{mirna_name}' \n",
    "        new_index.append(new_idx)\n",
    "        \n",
    "    else:\n",
    "        new_index.append(idx)\n",
    "\n",
    "# Update the DataFrame's index\n",
    "mut_data.index = new_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the sequence information from miRbase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the mirna target sequence \n",
    "mirbase = pd.read_csv(\"../microrna_data/mirbase_extended.csv\", index_col=0)\n",
    "\n",
    "# working on the RNA level\n",
    "mirbase[\"sequence_norm\"] = mirbase[\"sequence_norm\"].str.replace(\"T\", \"U\")\n",
    "mirbase[\"target\"] = mirbase[\"target\"].str.replace(\"T\", \"U\")\n",
    "\n",
    "# get only the high confidence microRNAs in mirbase\n",
    "mirbase_high_confidence = mirbase[mirbase[\"confidence\"] == \"high\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the original microRNA sequences\n",
    "mut_data[\"mirna_sequence\"] = mut_data[\"orig_mi\"].map(mirbase[\"sequence_norm\"])\n",
    "mut_data[\"mirna_sequence_orig\"] = mut_data[\"orig_mi\"].map(mirbase[\"sequence_orig\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the distribution of lengths in the original sequence?\n",
    "mut_data[\"mirna_sequence_orig\"].str.len().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# none of them are shorter than 21 nt (the target length)\n",
    "# drop the original sequence column\n",
    "mut_data = mut_data.drop(\"mirna_sequence_orig\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the added non-mutated data has no target sequence at this point\n",
    "# add target data based on mirbase\n",
    "for i, row in mut_data.iterrows():\n",
    "    if i.startswith(\"5.0_miRNA\"):\n",
    "        mut_data.loc[i, \"target\"] = mirbase.loc[row[\"orig_mi\"], \"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.2 - Manually investigate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the plot_folder\n",
    "plot_folder = os.path.join(base_plot_folder, \"5.2_manual_plotting\")\n",
    "\n",
    "# create it if it does not exist\n",
    "if not os.path.exists(plot_folder):\n",
    "    os.makedirs(plot_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.1 - Look at designs with an inserted A at positions 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all designs that contain insSeedA in their index\n",
    "insSeedA_designs = [design for design in mut_data.index if \"insSeedA\" in design]\n",
    "mut_data_seedA = mut_data.loc[insSeedA_designs, :]\n",
    "\n",
    "# Get the non-mutated designs that belong to the designs with insSeedA\n",
    "mirnas_seedA = mut_data.loc[insSeedA_designs, \"orig_mi\"]\n",
    "mut_data_nonmut_seedA = mut_data[mut_data[\"orig_mi\"].isin(mirnas_seedA)]\n",
    "mut_data_nonmut_seedA = mut_data_nonmut_seedA[mut_data_nonmut_seedA.index.str.startswith(\"5.0_miRNA\")]\n",
    "\n",
    "# Make sure these have the same order as the insSeedA designs (i.e., the order of \"orig_mi\" is the same)\n",
    "\n",
    "# Create a mapping of 'orig_mi' values to their order of appearance\n",
    "orig_mi_order = {mi: i for i, mi in enumerate(mut_data_seedA['orig_mi'])}\n",
    "# Map the 'orig_mi' in 'mut_data_nonmut_seedA' to their order\n",
    "mut_data_nonmut_seedA['order'] = mut_data_nonmut_seedA['orig_mi'].map(orig_mi_order)\n",
    "# Sort 'mut_data_nonmut_seedA' by the new 'order' column\n",
    "mut_data_nonmut_seedA_sorted = mut_data_nonmut_seedA.sort_values(by='order')\n",
    "# Drop the 'order' column\n",
    "mut_data_nonmut_seedA_sorted = mut_data_nonmut_seedA_sorted.drop(columns=['order'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2.4, 1.8))\n",
    "\n",
    "# flatten the data (unroll along cell lines)\n",
    "mut_data_seedA_flatten = mut_data_seedA[cell_lines_measured].values.flatten()\n",
    "mut_data_nonmut_seedA_flatten = mut_data_nonmut_seedA_sorted[cell_lines_measured].values.flatten()\n",
    "\n",
    "plt.scatter(mut_data_seedA_flatten, mut_data_nonmut_seedA_flatten, color=\"tab:blue\", s=6, rasterized=True)\n",
    "r2 = stats.pearsonr(mut_data_seedA_flatten, mut_data_nonmut_seedA_flatten)[0]**2\n",
    "plt.plot([-1.2, 0.1], [-1.2, 0.1], color=\"black\", linestyle=\"--\")\n",
    "plt.xlabel(r\"log$_{10}$(stability full target)\")\n",
    "plt.ylabel(r\"log$_{10}$(stability A at pos 1)\")\n",
    "plt.title(r\"r$^2$: \"+f\"{r2:.2f}\", fontsize=7.5)\n",
    "plt.tight_layout()\n",
    "for format in [\".png\", \".svg\"]:\n",
    "    plt.savefig(os.path.join(plot_folder, f\"5.2.1_scatterplot_seedA{format}\"), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.2 - Are the chosen microRNAs likely to have crosstalk?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from library2_utils.crosstalk import count_mismatches_in_region, region_split\n",
    "from library2_utils.NA_sequence_utilities import reverse_complement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_split(sequence, regions=[(0, 8), (8, 17), (17 ,21)]):\n",
    "    \"\"\"Splits a sequence into a list of regions, each of which is a string.\n",
    "    Assumes that the sequence is a miRNA sequence.\"\"\"\n",
    "    \n",
    "    return [sequence[region[0]:region[1]] for region in regions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let7 = mirbase_high_confidence.loc[\"hsa-let-7a-5p\", \"sequence_norm\"]\n",
    "print(let7)\n",
    "print(region_split(let7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatch_dict = {}\n",
    "\n",
    "for mirna_target, row in mirbase_high_confidence.iterrows():\n",
    "    intended_target = mirbase_high_confidence.loc[mirna_target, \"sequence_norm\"]\n",
    "    query_df = pd.DataFrame(index = mirbase_high_confidence.index, columns = [\"mismatch\", \"wobble\"])\n",
    "    for mirna_query, row in mirbase_high_confidence.iterrows():\n",
    "        query = mirbase_high_confidence.loc[mirna_query, \"sequence_norm\"]\n",
    "        mismatch, wobble = count_mismatches_in_region(intended_target, query, regions=[(0, 8), (8, 17), (17, 21)])\n",
    "        query_df.loc[mirna_query, \"mismatch\"] = mismatch\n",
    "        query_df.loc[mirna_query, \"wobble\"] = wobble\n",
    "\n",
    "    mismatch_dict[mirna_target] = query_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add columns that further summarize the mismatch data\n",
    "for key in mismatch_dict.keys():\n",
    "    df = mismatch_dict[key]\n",
    "    \n",
    "    # is there a mismatch in the seed region?\n",
    "    df[\"mismatch_seed\"] = df[\"mismatch\"].apply(lambda x: x[0])\n",
    "    \n",
    "    # is there a mismatch in the first 17 nts outside the seed?\n",
    "    df[\"mismatch_17nt\"] = df[\"mismatch\"].apply(lambda x: x[1])\n",
    "    \n",
    "    mismatch_dict[key] = df\n",
    "\n",
    "# filter to those with at most 4 mismatches in the first 17 nts\n",
    "# and 0 or 1 mismatches in the seed region\n",
    "mismatch_dict_filter = {}\n",
    "for key in mismatch_dict.keys():\n",
    "    df = mismatch_dict[key].copy()\n",
    "    df = df[df[\"mismatch_17nt\"] < 6]\n",
    "    mismatch_dict_filter[key] = df[df[\"mismatch_seed\"] < 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get miRNA expression data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.read_csv('../microrna_data/3_output/Alles_Keller_combined_expression_with_crosstalk.csv', index_col=0)\n",
    "used_mirna_data = df_combined\n",
    "used_mirna_name = \"combined_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_mirs_mut = mut_data[\"orig_mi\"].unique()\n",
    "unique_mirs_mut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_mirna_lin = 10**used_mirna_data\n",
    "\n",
    "for microrna in unique_mirs_mut:\n",
    "    print(\"----------------- NEW MIRNA ----------\")\n",
    "    print(f\"microRNA: {microrna}\")\n",
    "    #print(mismatch_dict_filter[microrna])\n",
    "    print(\"potentially crosstalking microRNAs:\")\n",
    "    indices = mismatch_dict_filter[microrna].index\n",
    "    for i in indices:\n",
    "        print(i, mirbase_high_confidence.loc[i, \"sequence_orig\"])\n",
    "    indices = [index for index in indices if index in used_mirna_data.index]\n",
    "    for index in indices:\n",
    "        print(\"---------------------------\")\n",
    "        print(f\"expression for miRNA {index}\")\n",
    "        print(used_mirna_data.loc[index, :])\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which microRNAs could have crosstalk based on this information?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "##### let-7a-5p and let-7i-5p\n",
    "These have massive crosstalk, as expected.\n",
    "\n",
    "##### miR-107\n",
    "hsa-miR-103a-3p AGCAGCATTGTACAGGGCTATGA\n",
    "hsa-miR-107     AGCAGCATTGTACAGGGCTATCA\n",
    "\n",
    "The expression for 103a-3p is almost always higher.\n",
    "However, these are the same miRNA for the first 21 nts (which is 100% of the bases I use).\n",
    "\n",
    "#### miR-16-5p\n",
    "hsa-miR-15a-5p TAGCAGCACATAATGGTTTGTG\n",
    "hsa-miR-16-5p  TAGCAGCACGTAAATATTGGCG\n",
    "hsa-miR-15b-5p TAGCAGCACATCATGGTTTACA\n",
    "hsa-miR-195-5p TAGCAGCACAGAAATATTGGC\n",
    "\n",
    "Expression is highly correlated. 16-5p has the highest expression, which probably means crosstalk doesn't matter all that much.\n",
    "The sequences match up until base 11 (with one wobble base pair) \n",
    "\n",
    "##### miR-19b-3p\n",
    "hsa-miR-19a-3p only has one mismatch: a wobble base pair at base 11.\n",
    "hsa-miR-19a-3p TGTGCAAATCTATGCAAAACTGA\n",
    "hsa-miR-19b-3p TGTGCAAATCCATGCAAAACTGA\n",
    "\n",
    "The expression levels are similar. The concrete mutation I used also has a mismatch with 19a-3p:\n",
    "5.1_miRNA_miR-19b-3p_mut11 AGTTTTGCATTGATTTGCACA\n",
    "\n",
    "##### mir-21-5p\n",
    "There is no predicted crosstalk at all.\n",
    "\n",
    "##### miR-22-3p\n",
    "Only predicted crosstalk is with miR-656-5p, which tiny expression levels (<100 tpm) in all cell lines\n",
    "\n",
    "##### mir-23a-3p\n",
    "There is no predicted crosstalk at all.\n",
    "\n",
    "Very much just maybe:\n",
    "hsa-miR-23a-3p ATCACATTGCCAGGGATTTCC\n",
    "hsa-miR-27a-3p TTCACAGTGGCTAAGTTCCGC\n",
    "hsa-miR-27b-3p TTCACAGTGGCTAAGTTCTGC\n",
    "These are highly expressed - maybe this explains somewhat weird deviant behavior?\n",
    "\n",
    "The target for mut7 is \"GGAAATCCCTGGCATTGTGAT\" with the reverse complement\n",
    "target ATCACAATGCCAGGGATTTCC\n",
    "23a-3p ATCACATTGCCAGGGATTTCC\n",
    "27a-3p TTCACAGTGGCTAAGTTCCGC\n",
    "27b-3p TTCACAGTGGCTAAGTTCTGC\n",
    "This turns a mismatch into a wobble base pair - not sure this is convincing enough to exclude it.\n",
    "\n",
    "##### miR-24-3p\n",
    "There is no predicted crosstalk at all. This hold even with strongly relaxed criteria.\n",
    "The outliers are probably not due to crosstalk.\n",
    "\n",
    "##### miR-31-3p\n",
    "There is no predicted crosstalk at all.\n",
    "\n",
    "##### miR-31-5p\n",
    "hsa-miR-31-5p  AGGCAAGATGCTGGCATAGCT\n",
    "hsa-miR-885-3p AGGCAGCGGGGTGTAGTGGATA\n",
    "\n",
    "Only predicted crosstalk is with miR-885-3p, which has tiny expression levels (<100 tpm) in all cell lines.\n",
    "The mismatches are probably significant enough that this should not confound the analysis.\n",
    "I also checked the sequencing data from the Keller lab - the expression of miR-885-3p is < 1000 tpm in all cell lines.\n",
    "\n",
    "##### miR-365a-3p\n",
    "hsa-miR-365a-3p TAATGCCCCTAAAAATCCTTAT\n",
    "hsa-miR-365b-3p TAATGCCCCTAAAAATCCTTAT\n",
    "Predicted crosstalk is with miR-365b-3p. This is not even in any of the expression data.\n",
    "Also, the sequence is absolutely identical.\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "Conclusion: let-7a-5p and let-7i-5p need to be filtered to build the initial model. miR-16-5p might be an issue.\n",
    "The others can be included without confounding the results. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.3 Add the mutation pattern as columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mirna_length = 21\n",
    "\n",
    "def one_hot_encoding(sequences: Union[list, str], alph: str = \"DNA\"):\n",
    "    \"\"\"Expects a list of sequences or a single string.\n",
    "\n",
    "    Returns a one-hot encoded numpy array.\"\"\"\n",
    "    alphabet = get_alphabet(alph)\n",
    "\n",
    "    # create mapping\n",
    "    char_to_int = {c: i for i, c in enumerate(alphabet)}\n",
    "    unpack_flag = False\n",
    "    if not isinstance(sequences, list):\n",
    "        unpack_flag = True\n",
    "        sequences = [sequences]\n",
    "    one_hot = np.zeros((len(sequences), len(sequences[0]), len(alphabet)))\n",
    "    for index, sequence in enumerate(sequences):\n",
    "        # convert to integer encoding\n",
    "        integer_encoded = [char_to_int[c] for c in sequence]\n",
    "        # one hot encoding\n",
    "        one_hot[index, :, :] = np.eye(len(alphabet))[integer_encoded]\n",
    "    if unpack_flag:\n",
    "        one_hot = one_hot.squeeze(axis=0)\n",
    "    return one_hot\n",
    "\n",
    "def get_alphabet(alph: str = \"DNA\"):\n",
    "    \"\"\"Returns the alphabet as a list.\"\"\"\n",
    "    DNA_alphabet = [\"A\", \"C\", \"G\", \"T\"]\n",
    "    RNA_alphabet = [\"A\", \"C\", \"G\", \"U\"]\n",
    "\n",
    "    if alph == \"DNA\":\n",
    "        return DNA_alphabet\n",
    "    elif alph == \"RNA\":\n",
    "        return RNA_alphabet\n",
    "    else:\n",
    "        raise ValueError(\"Invalid alphabet. Please choose 'DNA' or 'RNA'.\")\n",
    "\n",
    "def determine_mismatch_type(target_letter, mirna_letter):\n",
    "    match_dict = {\"A\": \"U\", \"U\": \"A\", \"C\": \"G\", \"G\": \"C\"}\n",
    "    wobble_dict = {\"A\": \"\", \"U\": \"G\", \"C\": \"\", \"G\": \"U\"}\n",
    "    \n",
    "    if match_dict[mirna_letter] == target_letter:\n",
    "        return 0\n",
    "    elif wobble_dict[mirna_letter] == target_letter:\n",
    "        return 2\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def extract_pattern_from_seq(target, mirna):\n",
    "    target = target[::-1]\n",
    "    # generate the initial pattern\n",
    "    pattern = [0]*len(target)\n",
    "    \n",
    "    for i in range(len(target)):\n",
    "        # check for seed A\n",
    "        if i==0 and target[i] == \"A\" and mirna[0] != \"U\":\n",
    "            # ignore this pattern\n",
    "            pattern[0] = 0\n",
    "            continue\n",
    "        pattern[i] = determine_mismatch_type(target[i], mirna[i])\n",
    "        \n",
    "    return pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the pattern\n",
    "for i, row in mut_data.iterrows():\n",
    "    target = row[\"target\"]\n",
    "    mirna = row[\"mirna_sequence\"]\n",
    "    pattern = extract_pattern_from_seq(target=target, mirna=mirna)\n",
    "    mut_data.loc[i, \"pattern\"] = str(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the total number of mismatches and wobbles\n",
    "mut_data[\"mismatches\"] = mut_data[\"pattern\"].apply(lambda x: ast.literal_eval(x).count(1))\n",
    "mut_data[\"wobbles\"] = mut_data[\"pattern\"].apply(lambda x: ast.literal_eval(x).count(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get only those with a single mismatch or wobble\n",
    "single_mm = mut_data[(mut_data[\"mismatches\"] == 1) & (mut_data[\"wobbles\"] == 0)]\n",
    "single_wobble = mut_data[(mut_data[\"wobbles\"] == 1) & (mut_data[\"mismatches\"] == 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the pattern info\n",
    "\n",
    "Here, we create a \"training_df\" which contains a) the pattern info of the mutations and b) is unrolled along the cell lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_columns = [f\"pos_{i+1}\" for i in range(mirna_length)]\n",
    "training_df_columns = position_columns.copy()\n",
    "training_df_columns.append(\"knockdown_orig\")\n",
    "training_df_columns.append(\"knockdown_mut\")\n",
    "training_df_columns.append(\"orig_mi\")\n",
    "training_df_columns.append(\"cell_line\")\n",
    "training_df_columns.append(\"mismatches\")\n",
    "training_df_columns.append(\"wobbles\")\n",
    "\n",
    "# create a new empty dataframe\n",
    "training_df = pd.DataFrame(columns=training_df_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the knockdown of the non-mutated mirna\n",
    "# even though this is called knockdown, it's currently just the log10 of the stability\n",
    "# it'll get converted to knockdown later\n",
    "for i, row in mut_data.iterrows():\n",
    "    # get the original miRNA name\n",
    "    orig_mi = row[\"orig_mi\"]\n",
    "    \n",
    "    # get rid of the \"hsa-\" prefix\n",
    "    orig_mi_short = \"-\".join(orig_mi.split(\"-\")[1:])\n",
    "    \n",
    "    non_mut_index = f\"5.0_miRNA_{orig_mi_short}\"\n",
    "    for cell_line in cell_lines_measured:\n",
    "        # add the knockdown for the non-mutated miRNA\n",
    "        knockdown_orig = mut_data.loc[non_mut_index, cell_line]\n",
    "        \n",
    "        # ALTERNATIVE: TRY THE PREDICTED KNOCKDOWN\n",
    "        # this is probably not a good idea, since, e.g., miR-21 is off in some cell lines\n",
    "        # knockdown_orig = np.log10(predicted_knockdown.loc[orig_mi, cell_line])\n",
    "        \n",
    "        # get the other data\n",
    "        knockdown_mut = row[cell_line]\n",
    "        mismatches = row[\"mismatches\"]\n",
    "        wobbles = row[\"wobbles\"]\n",
    "        pattern = ast.literal_eval(row[\"pattern\"])\n",
    "        new_index = f\"{i}_{cell_line}\"\n",
    "        # orig_mi = row[\"orig_mi\"]\n",
    "        \n",
    "        # add the new row\n",
    "        new_row = pattern + [knockdown_orig, knockdown_mut, orig_mi, cell_line, mismatches, wobbles]\n",
    "        training_df.loc[new_index] = new_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out let-7 microRNAs (these are harder to interpret due to crosstalk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confounding_microRNAs = [\"hsa-let-7a-5p\", \"hsa-let-7i-5p\"]\n",
    "training_df_confound = training_df[training_df[\"orig_mi\"].isin(confounding_microRNAs)]\n",
    "training_df = training_df[~training_df[\"orig_mi\"].isin(confounding_microRNAs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df_confound[\"orig_mi\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.4 - Single-mutation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter to those with only one mutation or wobble\n",
    "training_df_filter_mismatch = training_df[(training_df[\"mismatches\"] == 1) & (training_df[\"wobbles\"] == 0)]\n",
    "training_df_filter_wobble = training_df[(training_df[\"mismatches\"] == 0) & (training_df[\"wobbles\"] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column that specifies the name of the region where the mismatch occurs (column name)\n",
    "for i, row in training_df_filter_mismatch.iterrows():\n",
    "    # bin based on individual positions\n",
    "    for col in position_columns:\n",
    "        # for mismatch: 1; for wobble: 2\n",
    "        if row[col] == 1:\n",
    "            training_df_filter_mismatch.loc[i, \"region\"] = col.split(\"_\")[1]\n",
    "            break\n",
    "\n",
    "for i, row in training_df_filter_wobble.iterrows():\n",
    "    # bin based on individual positions\n",
    "    for col in position_columns:\n",
    "        # for mismatch: 1; for wobble: 2\n",
    "        if row[col] == 2:\n",
    "            training_df_filter_wobble.loc[i, \"region\"] = col.split(\"_\")[1]\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### convert to linear-fold change data (knockdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this converts the stability to knockdown (1/stability)\n",
    "training_df_filter_mismatch[\"knockdown_orig\"] = 1/10**training_df_filter_mismatch[\"knockdown_orig\"]\n",
    "training_df_filter_mismatch[\"knockdown_mut\"] = 1/10**training_df_filter_mismatch[\"knockdown_mut\"]\n",
    "\n",
    "training_df_filter_wobble[\"knockdown_orig\"] = 1/10**training_df_filter_wobble[\"knockdown_orig\"]\n",
    "training_df_filter_wobble[\"knockdown_mut\"] = 1/10**training_df_filter_wobble[\"knockdown_mut\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set values smaller than 1 to 1\n",
    "training_df_filter_mismatch.loc[training_df_filter_mismatch[\"knockdown_orig\"] < 1, \"knockdown_orig\"] = 1\n",
    "training_df_filter_mismatch.loc[training_df_filter_mismatch[\"knockdown_mut\"] < 1, \"knockdown_mut\"] = 1\n",
    "\n",
    "training_df_filter_wobble.loc[training_df_filter_wobble[\"knockdown_orig\"] < 1, \"knockdown_orig\"] = 1\n",
    "training_df_filter_wobble.loc[training_df_filter_wobble[\"knockdown_mut\"] < 1, \"knockdown_mut\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter to those with non-mutated knockdown between two limits\n",
    "upper_limit = 100\n",
    "lower_limit = 3\n",
    "\n",
    "df_filter_plot_mm = training_df_filter_mismatch[(training_df_filter_mismatch[\"knockdown_orig\"] > lower_limit ) &\\\n",
    "                                                (training_df_filter_mismatch[\"knockdown_orig\"] < upper_limit)]\n",
    "df_filter_plot_wobble = training_df_filter_wobble[(training_df_filter_wobble[\"knockdown_orig\"] > lower_limit ) & \\\n",
    "                                                (training_df_filter_wobble[\"knockdown_orig\"] < upper_limit)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert to relative fold-change data and merge the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the knockdown values\n",
    "# We want the relative knockdown, so we divide by the non-mutated knockdown\n",
    "# One is subtracted from both so that 0 knockdown means no effect\n",
    "df_filter_plot_mm[\"knockdown_mut\"] = (df_filter_plot_mm[\"knockdown_mut\"]-1)/(df_filter_plot_mm[\"knockdown_orig\"]-1)\n",
    "df_filter_plot_wobble[\"knockdown_mut\"] = (df_filter_plot_wobble[\"knockdown_mut\"]-1)/(df_filter_plot_wobble[\"knockdown_orig\"]-1)\n",
    "\n",
    "# Add an identifier column to each DataFrame to distinguish mismatches and wobbles\n",
    "df_filter_plot_mm['type'] = 'Mismatch'\n",
    "df_filter_plot_wobble['type'] = 'Wobble'\n",
    "\n",
    "# Concatenate the two DataFrames\n",
    "df_combined = pd.concat([df_filter_plot_mm, df_filter_plot_wobble])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define limits to median mutation impacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_impact_limit = 0.08\n",
    "medium_impact_limit = 0.3\n",
    "low_impact_limit = 0.65\n",
    "\n",
    "impact_dict_mm = {}\n",
    "impact_dict_wobble = {}\n",
    "median_list_mm = []\n",
    "median_list_wobble = []\n",
    "for column in position_columns:\n",
    "    median_mm = df_filter_plot_mm[df_filter_plot_mm[\"region\"] == column.split(\"_\")[-1]][\"knockdown_mut\"].median()\n",
    "    median_wobble = df_filter_plot_wobble[df_filter_plot_wobble[\"region\"] == column.split(\"_\")[-1]][\"knockdown_mut\"].median()\n",
    "    median_list_mm.append(median_mm)\n",
    "    median_list_wobble.append(median_wobble)\n",
    "    \n",
    "    if median_mm < high_impact_limit:\n",
    "        impact_dict_mm[column] = \"high\"\n",
    "    elif median_mm < medium_impact_limit:\n",
    "        impact_dict_mm[column] = \"mid\"\n",
    "    elif median_mm < low_impact_limit:\n",
    "        impact_dict_mm[column] = \"low\"\n",
    "    else:\n",
    "        impact_dict_mm[column] = \"no\"\n",
    "    \n",
    "    if median_wobble < high_impact_limit:\n",
    "        impact_dict_wobble[column] = \"high\"\n",
    "    elif median_wobble < medium_impact_limit:\n",
    "        impact_dict_wobble[column] = \"mid\"\n",
    "    elif median_wobble < low_impact_limit:\n",
    "        impact_dict_wobble[column] = \"low\"\n",
    "    else:\n",
    "        impact_dict_wobble[column] = \"no\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the impact dictionaries as a dataframe\n",
    "output_folder = f\"../outputs/5_mutations\"\n",
    "\n",
    "# create it if it does not exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# create the df\n",
    "mutation_impact_df = pd.DataFrame.from_dict(impact_dict_mm, orient=\"index\", columns=[\"mismatch\"])\n",
    "# add wobble data\n",
    "mutation_impact_df[\"wobble\"] = mutation_impact_df.index.to_series().apply(lambda x: impact_dict_wobble[x])\n",
    "\n",
    "# wherever wobble is \"high\" and mismatch is \"mid\", make wobble \"mid\"\n",
    "mutation_impact_df[\"wobble\"] = np.where((mutation_impact_df[\"wobble\"] == \"high\") & (mutation_impact_df[\"mismatch\"] == \"mid\"), \"mid\", mutation_impact_df[\"wobble\"])\n",
    "# wherever mismatch is \"no\" and wobble is \"low\", make wobble \"no\"\n",
    "mutation_impact_df[\"wobble\"] = np.where((mutation_impact_df[\"wobble\"] == \"low\") & (mutation_impact_df[\"mismatch\"] == \"no\"), \"no\", mutation_impact_df[\"wobble\"])\n",
    "\n",
    "mutation_impact_df.to_csv(os.path.join(output_folder, \"mutation_impact.csv\"))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutation_impact_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create boxplots without p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = [str(i) for i in np.arange(1, 22, 1)]\n",
    "\n",
    "plt.figure(figsize=(3, 1.6))\n",
    "sns.boxplot(x=\"region\", y=\"knockdown_mut\", data=df_filter_plot_mm, order=order, dodge=True, color=\"skyblue\",\n",
    "            boxprops={'edgecolor': 'black', },\n",
    "            whiskerprops={'color': 'black'},\n",
    "            capprops={'color': 'black'},\n",
    "            medianprops={'color': 'black'},\n",
    "            linewidth=1,\n",
    "            showfliers=True,\n",
    "            flierprops=dict(marker='o', markersize=3, markerfacecolor='black', markeredgewidth=0, linestyle='none'),\n",
    "            zorder=2)\n",
    "\n",
    "# draw lines at the impact limits\n",
    "plt.axhline(y=high_impact_limit, color='red', linestyle='--', alpha=0.5, linewidth=1)\n",
    "plt.axhline(y=medium_impact_limit, color='red', linestyle='--', alpha=0.5, linewidth=1)\n",
    "plt.axhline(y=low_impact_limit, color='red', linestyle='--', alpha=0.5, linewidth=1)\n",
    "\n",
    "# rotate xticks by 90 degrees\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel(\"position along microRNA\")\n",
    "plt.ylabel(\"ratio of knockdown\\n( mutated / non-mutated )\")\n",
    "plt.title(f\"Effect of a single target site mutation\", fontsize=7)\n",
    "\n",
    "plt.text(21, -0.05, \"h\", color=\"black\", fontsize=7, rotation=0)\n",
    "plt.text(21, 0.15, \"m\", color=\"black\", fontsize=7, rotation=0)\n",
    "plt.text(21, 0.45, \"l\", color=\"black\", fontsize=7, rotation=0)\n",
    "plt.text(21, 0.85, \"n\", color=\"black\", fontsize=7, rotation=0)\n",
    "\n",
    "plt.ylim(0, 1.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "for format in [\".png\", \".svg\"]:\n",
    "    plt.savefig(f\"{plot_folder}/5.2.4_single_mut_boxplot_no_wobble_{lower_limit}to{upper_limit}{format}\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = [str(i) for i in np.arange(1, 22, 1)]\n",
    "\n",
    "plt.figure(figsize=(6, 3))\n",
    "sns.boxplot(x=\"region\", y=\"knockdown_mut\", hue=\"type\", data=df_combined, order=order, dodge=True,\n",
    "            showfliers=True, flierprops=dict(marker='o', markersize=3, markerfacecolor='black', linestyle='none'))\n",
    "\n",
    "# draw lines at 0.2 and 0.5\n",
    "plt.axhline(y=high_impact_limit, color='grey', linestyle='--', alpha=0.5)\n",
    "plt.axhline(y=medium_impact_limit, color='grey', linestyle='--', alpha=0.5)\n",
    "plt.axhline(y=low_impact_limit, color='grey', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.xlabel(\"Position along microRNA\")\n",
    "plt.ylabel(\"Ratio of knockdown (mut/non-mut)\")\n",
    "plt.title(f\"Effect of a single mutation\\n{lower_limit} < original knockdown < {upper_limit}\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "for format in [\".png\", \".svg\"]:\n",
    "    plt.savefig(f\"{plot_folder}/5.2.4_single_mut_boxplot_{lower_limit}to{upper_limit}{format}\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "# for each miRNA, plot a histogram of \"knockdown_mut\"\n",
    "for mirna in df_filter_plot_mm[\"orig_mi\"].unique():\n",
    "    df_mirna = df_filter_plot_mm[df_filter_plot_mm[\"orig_mi\"] == mirna]\n",
    "    plt.figure(figsize=(2.4, 1.8))\n",
    "    sns.histplot(data=df_mirna, x=\"knockdown_mut\", bins=20)\n",
    "    plt.title(f\"{mirna}\")\n",
    "    plt.xlabel(\"Ratio of knockdown (mut/non-mut)\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.tight_layout()\n",
    "    for format in [\".png\", \".svg\"]:\n",
    "        plt.savefig(f\"{plot_folder}/5.2.5_single_mut_hist_{mirna}{format}\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mirna = df_filter_plot_mm[df_filter_plot_mm[\"orig_mi\"] == \"hsa-miR-23a-3p\"]\n",
    "df_mirna.sort_values(by=\"knockdown_mut\", inplace=True, ascending=False)\n",
    "df_mirna[df_mirna[\"region\"] == \"7\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot with p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# Perform Mann-Whitney U Test for each region\n",
    "results = [] \n",
    "for region in df_combined['region'].unique():\n",
    "    group1 = df_combined[(df_combined['region'] == region) & (df_combined['type'] == 'Mismatch')]['knockdown_mut']\n",
    "    group2 = df_combined[(df_combined['region'] == region) & (df_combined['type'] == 'Wobble')]['knockdown_mut']\n",
    "    # check if both groups are non-empty\n",
    "    if len(group1) == 0 or len(group2) == 0:\n",
    "        continue\n",
    "    stat, p_value = mannwhitneyu(group1, group2)\n",
    "    results.append((region, p_value))\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "df_p_values = pd.DataFrame(results, columns=['region', 'p_value'])\n",
    "\n",
    "# Sort df_p_values according to the predefined order\n",
    "df_p_values['order'] = df_p_values['region'].apply(lambda x: order.index(x))\n",
    "df_p_values_sorted = df_p_values.sort_values('order').drop('order', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_significance(ax, df_p_values, df_combined, order, height_factor=1.05, height=False):\n",
    "    if not height:\n",
    "        y_max = df_combined['knockdown_mut'].max()\n",
    "        line_offset = y_max*0.02\n",
    "    else:\n",
    "        y_max = height\n",
    "        line_offset = y_max*0.02\n",
    "    \n",
    "    for region in order:  # Iterate based on the specified order\n",
    "        p_value = df_p_values.loc[df_p_values_sorted['region'] == region, 'p_value'].values\n",
    "        # if non-empy, extract position 0\n",
    "        p_value = p_value[0] if len(p_value) > 0 else None\n",
    "        # Annotation text based on p-value\n",
    "        if p_value is None:\n",
    "            text = 'ns'\n",
    "        elif p_value < 0.001:\n",
    "            text = '***'\n",
    "        elif p_value < 0.01:\n",
    "            text = '**'\n",
    "        elif p_value < 0.05:\n",
    "            text = '*'\n",
    "        else:\n",
    "            text = 'ns'\n",
    "        \n",
    "        # get the current y value (the highest value in the current region)\n",
    "        # y_max = df_combined[df_combined['region'] == region]['knockdown_mut'].max()\n",
    "        \n",
    "        x_loc = order.index(region)  # x location is based directly on the order list\n",
    "        ax.text(x_loc, y_max * height_factor, text, ha='center', va='bottom')\n",
    "        \n",
    "        line_y = y_max * (height_factor - 0.5 * line_offset)  # Adjust line position\n",
    "        ax.hlines(line_y, x_loc - 0.2, x_loc + 0.2, color=\"black\", linewidth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting and annotating\n",
    "plt.figure(figsize=(6, 2.4))\n",
    "ax = sns.boxplot(x=\"region\", y=\"knockdown_mut\", hue=\"type\", data=df_combined, order=order, dodge=True,\n",
    "                 showfliers=True, flierprops=dict(marker='o', markersize=3, markerfacecolor='black', linestyle='none'))\n",
    "annotate_significance(ax, df_p_values_sorted, df_combined, order, height=1.55)\n",
    "\n",
    "# draw lines at 0.2 and 0.5\n",
    "plt.axhline(y=high_impact_limit, color='grey', linestyle='--', alpha=0.7)\n",
    "plt.axhline(y=medium_impact_limit, color='grey', linestyle='--', alpha=0.7)\n",
    "plt.axhline(y=low_impact_limit, color='grey', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.xlabel(\"Position along the microRNA\")\n",
    "plt.ylabel(\"Ratio of knockdown (mut/non-mut)\")\n",
    "\n",
    "plt.xlim(-1, 21)\n",
    "plt.ylim(0, 1.8)\n",
    "plt.title(f\"Effect of a single mismatch or wobble on the relative knockdown [knockdown = (1/stability) - 1]\\nrestricted to {lower_limit} < non-mutated knockdown < {upper_limit} to reduce noise\", fontsize=7.5)\n",
    "plt.legend(loc = [0.15, 0.65])\n",
    "\n",
    "plt.text(21.55, -0.05, \"high\", color=\"black\", fontsize=7, rotation=0)\n",
    "plt.text(21.5, 0.15, \"medium\", color=\"black\", fontsize=7, rotation=0)\n",
    "plt.text(21.5, 0.45, \"low\", color=\"black\", fontsize=7, rotation=0)\n",
    "plt.text(21.5, 0.85, \"none\", color=\"black\", fontsize=7, rotation=0)\n",
    "plt.text(21.5, 1.2, \"impact:\", color=\"black\", fontsize=8, rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "for format in [\".png\", \".svg\"]:\n",
    "    plt.savefig(f\"{plot_folder}/5.2.4_single_mut_boxplot_{lower_limit}to{upper_limit}_with_significance{format}\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.6 - Boxplots by the pre-defined prefix (essentially, location in or outside the seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df[\"prefix\"] = training_df.index.str[:4]\n",
    "training_df_confound[\"prefix\"] = training_df_confound.index.str[:4]\n",
    "training_df[\"prefix\"] = training_df[\"prefix\"].str.replace(\"_\", \"\")\n",
    "training_df_confound[\"prefix\"] = training_df_confound[\"prefix\"].str.replace(\"_\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for those with the prefix 5.1, add an a if mm_1_9 is 1, else add a b\n",
    "for i, row in training_df.iterrows():\n",
    "    # find the position of the mismatch\n",
    "    pattern = row[position_columns].to_list()\n",
    "    if row[\"prefix\"] == \"5.1\":\n",
    "        try:\n",
    "            pos = pattern.index(1)\n",
    "            if pos < 8:\n",
    "                training_df.loc[i, \"prefix\"] = \"5.1a\"\n",
    "            else:\n",
    "                training_df.loc[i, \"prefix\"] = \"5.1b\"\n",
    "        except ValueError:\n",
    "            training_df.loc[i, \"prefix\"] = \"5.0\"\n",
    "            \n",
    "    if row[\"prefix\"] == \"5.2\":\n",
    "        try:\n",
    "            pos = pattern.index(2)\n",
    "            if pos < 8:\n",
    "                training_df.loc[i, \"prefix\"] = \"5.2a\"\n",
    "            else:\n",
    "                training_df.loc[i, \"prefix\"] = \"5.2b\"\n",
    "        except ValueError:\n",
    "            training_df.loc[i, \"prefix\"] = \"5.0\"\n",
    "         \n",
    "for i, row in training_df_confound.iterrows():\n",
    "    # find the position of the mismatch\n",
    "    pattern = row[position_columns].to_list()\n",
    "    if row[\"prefix\"] == \"5.1\":\n",
    "        try:\n",
    "            pos = pattern.index(1)\n",
    "            if pos < 8:\n",
    "                training_df_confound.loc[i, \"prefix\"] = \"5.1a\"\n",
    "            else:\n",
    "                training_df_confound.loc[i, \"prefix\"] = \"5.1b\"\n",
    "        except ValueError:\n",
    "            training_df_confound.loc[i, \"prefix\"] = \"5.0\"\n",
    "            \n",
    "    if row[\"prefix\"] == \"5.2\":\n",
    "        try:\n",
    "            pos = pattern.index(2)\n",
    "            if pos < 8:\n",
    "                training_df_confound.loc[i, \"prefix\"] = \"5.2a\"\n",
    "            else:\n",
    "                training_df_confound.loc[i, \"prefix\"] = \"5.2b\"\n",
    "        except ValueError:\n",
    "            training_df_confound.loc[i, \"prefix\"] = \"5.0\"      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop those with prefix 5.3 (A in seed, doesn't act as a mutation)\n",
    "training_df = training_df[training_df[\"prefix\"] != \"5.3\"]\n",
    "training_df_confound = training_df_confound[training_df_confound[\"prefix\"] != \"5.3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_dict = {\n",
    " '5.0': {},\n",
    " '5.1a': {'n_mut_seed': 1},\n",
    " '5.1b': {'n_mut_outside': 1},\n",
    " '5.2a': {'n_wobble_seed': 1},\n",
    " '5.2b': {'n_wobble_outside': 1},\n",
    " '5.4': {'n_mut_seed': 2},\n",
    " '5.5': {'n_wobble_seed': 2},\n",
    " '5.6': {'n_mut_seed': 1, 'n_mut_outside': 1},\n",
    " '5.7': {'n_wobble_seed': 1, 'n_mut_outside': 1},\n",
    " '5.8': {'n_mut_outside': 2},\n",
    " '5.9': {'n_mut_outside': 1, 'n_wobble_outside': 1},\n",
    " '5.10': {'n_wobble_outside': 2},\n",
    " '5.11': {'n_mut_seed': 2, 'n_mut_outside': 1},\n",
    " '5.12': {'n_mut_seed': 1, 'n_mut_outside': 2},\n",
    " '5.13': {'n_mut_seed': 1, 'n_mut_outside': 1, 'n_wobble_outside': 1},\n",
    " '5.14': {'n_mut_outside': 3},\n",
    " '5.15': {'n_mut_outside': 2, 'n_wobble_outside': 1},\n",
    " '5.16': {'n_mut_outside': 1, 'n_wobble_outside': 2},\n",
    " '5.17': {'n_wobble_outside': 3},\n",
    " '5.18': {'n_mut_seed': 1, 'n_mut_outside': 3},\n",
    " '5.19': {'n_mut_seed': 1, 'n_mut_outside': 2, 'n_wobble_outside': 1},\n",
    " '5.20': {'n_mut_seed': 1, 'n_mut_outside': 1, 'n_wobble_outside': 2},\n",
    " '5.21': {'n_mut_outside': 4},\n",
    " '5.22': {'n_mut_outside': 3, 'n_wobble_outside': 1},\n",
    " '5.23': {'n_mut_outside': 2, 'n_wobble_outside': 2},\n",
    " '5.24': {'n_mut_outside': 1, 'n_wobble_outside': 3},\n",
    " '5.25': {'n_mut_seed': 1, 'n_mut_outside': 4},\n",
    " '5.26': {'n_mut_seed': 1, 'n_mut_outside': 3, 'n_wobble_outside': 1},\n",
    " '5.27': {'n_mut_seed': 1, 'n_mut_outside': 2, 'n_wobble_outside': 2},\n",
    " '5.28': {'n_mut_outside': 5},\n",
    " '5.29': {'n_mut_outside': 3, 'n_wobble_outside': 2},\n",
    " '5.30': {'n_mut_seed': 1, 'n_mut_outside': 5},\n",
    " '5.31': {'n_mut_outside': 6},\n",
    " '5.32': {'n_mut_outside': 4, 'n_wobble_outside': 2}\n",
    "}\n",
    "\n",
    "# create xticklabels based on this\n",
    "xticklabels = []\n",
    "median_classification_dict = {}\n",
    "check_keys = [\"n_mut_seed\", \"n_mut_outside\", \"n_wobble_seed\", \"n_wobble_outside\"]\n",
    "for key, value in prefix_dict.items():\n",
    "    key_numbers = []\n",
    "    for check_key in check_keys:\n",
    "        if check_key in value:\n",
    "            key_numbers.append(value[check_key])\n",
    "        else:\n",
    "            key_numbers.append(0)\n",
    "            \n",
    "    xticklabels.append(f\"{key_numbers[0]}\\n{key_numbers[1]}\\n{key_numbers[2]}\\n{key_numbers[3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 2.4))\n",
    "\n",
    "sns.boxplot(x=\"prefix\", y=\"knockdown_mut\", data=training_df, showfliers=True, order=prefix_dict.keys(), color=\"tab:blue\",\n",
    "            flierprops=dict(marker='o', markersize=1, markerfacecolor='black', linestyle='none'))\n",
    "plt.xticks(ticks=np.arange(len(prefix_dict)), labels=xticklabels)\n",
    "\n",
    "plt.ylabel(r\"log$_{10}$(stability)\")\n",
    "plt.tight_layout()\n",
    "plt.xlabel(\"   # mutations in seed\\n\" +\n",
    "            \"            # mutations outside seed\\n\" +\n",
    "            \"# wobbles in seed\\n\"+\n",
    "            \"        # wobbles outside seed\")\n",
    "for format in [\".png\", \".svg\"]:\n",
    "    plt.savefig(f\"{plot_folder}/5.2.6_training_df_boxplot.{format}\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 2.4))\n",
    "\n",
    "sns.boxplot(x=\"prefix\", y=\"knockdown_mut\", data=training_df_confound, showfliers=True, order=prefix_dict.keys(), color=\"tab:blue\",\n",
    "            flierprops=dict(marker='o', markersize=1, markerfacecolor='black', linestyle='none'))\n",
    "plt.xticks(ticks=np.arange(len(prefix_dict)), labels=xticklabels)\n",
    "\n",
    "plt.ylabel(r\"log$_{10}$(stability)\")\n",
    "plt.tight_layout()\n",
    "plt.xlabel(\"   # mutations in seed\\n\" +\n",
    "            \"            # mutations outside seed\\n\" +\n",
    "            \"# wobbles in seed\\n\"+\n",
    "            \"        # wobbles outside seed\")\n",
    "for format in [\".png\", \".svg\"]:\n",
    "    plt.savefig(f\"{plot_folder}/5.2.6_training_df_confound_boxplot.{format}\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.7 - Boxplot by the classified mutation impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_median_mut_classification(input_df, impact_df):\n",
    "    df = input_df.copy()\n",
    "    position_columns = [col for col in df.columns if \"pos_\" in col]\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        # get all mutation positions\n",
    "        positions_mut = []\n",
    "        for col in position_columns:\n",
    "            if row[col] == 1:\n",
    "                positions_mut.append(col)\n",
    "                \n",
    "        # get all wobble positions\n",
    "        positions_wobble = []\n",
    "        for col in position_columns:\n",
    "            if row[col] == 2:\n",
    "                positions_wobble.append(col)\n",
    "                \n",
    "        no_high_impact = 0\n",
    "        no_mid_impact = 0\n",
    "        no_low_impact = 0\n",
    "        no_no_impact = 0\n",
    "        \n",
    "        for pos in positions_mut:\n",
    "            if impact_df.loc[pos, \"mismatch\"] == \"high\":\n",
    "                no_high_impact += 1\n",
    "            elif impact_df.loc[pos, \"mismatch\"] == \"mid\":\n",
    "                no_mid_impact += 1\n",
    "            elif impact_df.loc[pos, \"mismatch\"] == \"low\":\n",
    "                no_low_impact += 1\n",
    "            elif impact_df.loc[pos, \"mismatch\"] == \"no\":\n",
    "                no_no_impact += 1\n",
    "        for pos in positions_wobble:\n",
    "            if impact_df.loc[pos, \"wobble\"] == \"high\":\n",
    "                no_high_impact += 1\n",
    "            elif impact_df.loc[pos, \"wobble\"] == \"mid\":\n",
    "                no_mid_impact += 1\n",
    "            elif impact_df.loc[pos, \"wobble\"] == \"low\":\n",
    "                no_low_impact += 1\n",
    "            elif impact_df.loc[pos, \"wobble\"] == \"no\":\n",
    "                no_no_impact += 1\n",
    "                \n",
    "        df.loc[index, \"no_high_impact\"] = no_high_impact\n",
    "        df.loc[index, \"no_mid_impact\"] = no_mid_impact\n",
    "        df.loc[index, \"no_low_impact\"] = no_low_impact\n",
    "        df.loc[index, \"no_no_impact\"] = no_no_impact\n",
    "        df.loc[index, \"no_total_impact\"] = no_high_impact + no_mid_impact + no_low_impact + no_no_impact\n",
    "        \n",
    "    df[\"classification\"] = df[\"no_high_impact\"].astype(int).astype(str) + \"\\n\" +\\\n",
    "                            df[\"no_mid_impact\"].astype(int).astype(str) + \"\\n\" + \\\n",
    "                            df[\"no_low_impact\"].astype(int).astype(str) + \"\\n\" + \\\n",
    "                            df[\"no_no_impact\"].astype(int).astype(str) + \"\\n\" + \\\n",
    "                            df[\"no_total_impact\"].astype(int).astype(str)\n",
    "    \n",
    "    # for those with a total larger than 4, set the classification to >4\n",
    "    df.loc[df[\"no_total_impact\"] > 4, \"classification\"] = \"\\n\\n\\n\\n>4\"\n",
    "    \n",
    "     # Summarize classification with threshold\n",
    "    def summarize_impact(x, threshold=1):\n",
    "        return '>{}'.format(threshold) if x > threshold else str(int(x))\n",
    "    \n",
    "    df[\"summary_high_impact\"] = df[\"no_high_impact\"].apply(lambda x: summarize_impact(x, 1))\n",
    "    df[\"summary_mid_impact\"] = df[\"no_mid_impact\"].apply(lambda x: summarize_impact(x, 2))\n",
    "    df[\"summary_low_impact\"] = df[\"no_low_impact\"].apply(lambda x: summarize_impact(x, 3))\n",
    "    df[\"summary_no_impact\"] = df[\"no_no_impact\"].apply(lambda x: summarize_impact(x, 3))\n",
    "    \n",
    "    df[\"classification_summary\"] = df[\"summary_high_impact\"] + \"\\n\" + df[\"summary_mid_impact\"] + \"\\n\" + \\\n",
    "                                    df[\"summary_low_impact\"] + \"\\n\" + df[\"summary_no_impact\"]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df  = get_median_mut_classification(training_df, mutation_impact_df)\n",
    "training_df_confound = get_median_mut_classification(training_df_confound, mutation_impact_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6.5, 2.4))\n",
    "\n",
    "sns.boxplot(x=\"classification\", y=\"knockdown_mut\", data=training_df, showfliers=True, color=\"tab:blue\",\n",
    "            flierprops=dict(marker='o', markersize=1, markerfacecolor='black', linestyle='none'))\n",
    "plt.ylabel(r\"log$_{10}$(stability)\")\n",
    "\n",
    "plt.xticks(fontsize = 6)\n",
    "plt.tight_layout()\n",
    "plt.xlabel(\"          # mutations high impact\\n\" +\n",
    "        \"                # mutations medium impact\\n\" +\n",
    "        \"         # mutations low impact\\n\" +\n",
    "        \"        # mutations no impact\\n\" +\n",
    "        \"# mutations total\")\n",
    "\n",
    "for format in [\".png\", \".svg\"]:\n",
    "    plt.savefig(f\"{plot_folder}/5.2.7_training_df_boxplot_impact.{format}\", dpi=300)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6.5, 2.4))\n",
    "\n",
    "sns.boxplot(x=\"classification\", y=\"knockdown_mut\", data=training_df_confound, showfliers=True, color=\"tab:blue\",\n",
    "            flierprops=dict(marker='o', markersize=1, markerfacecolor='black', linestyle='none'))\n",
    "plt.ylabel(r\"log$_{10}$(stability)\")\n",
    "\n",
    "plt.xticks(fontsize = 6)\n",
    "plt.tight_layout()\n",
    "plt.xlabel(\"          # mutations high impact\\n\" +\n",
    "        \"                # mutations medium impact\\n\" +\n",
    "        \"         # mutations low impact\\n\" +\n",
    "        \"        # mutations no impact\\n\" +\n",
    "        \"# mutations total\")\n",
    "\n",
    "for format in [\".png\", \".svg\"]:\n",
    "    plt.savefig(f\"{plot_folder}/5.2.7_training_df_confound_boxplot_impact.{format}\", dpi=300)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.3 - Can we predict mutation impact using a heuristic model?\n",
    "\n",
    "Here, we try to predict the impact of mutations by looking up the impact of individual mutations for the same miRNA and in the same cell line. We look either at a) the mutation with the maximum impact, b) the sum of the impact of the mutation, c) the product of the impact of the mutation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mutations = training_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out single mutations and non-mutated miRNAs\n",
    "\n",
    "no_mutations_index = [design for design in all_mutations.index if \"5.0_miRNA\" in design]\n",
    "single_mutations_index = [design for design in all_mutations.index if \"5.1_miRNA\" in design]\n",
    "single_mutations = all_mutations.loc[single_mutations_index, :]\n",
    "single_wobble_index = [design for design in all_mutations.index if \"5.2_miRNA\" in design]\n",
    "single_wobbles = all_mutations.loc[single_wobble_index, :]\n",
    "all_mutations = all_mutations.drop(single_mutations_index)\n",
    "all_mutations = all_mutations.drop(single_wobble_index)\n",
    "all_mutations = all_mutations.drop(no_mutations_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert single mutations to a dictionary containing cell line, microRNA, and position of the mutation\n",
    "single_mutation_dict = {}\n",
    "for i, row in single_mutations.iterrows():\n",
    "    cell_line = row[\"cell_line\"]\n",
    "    miRNA = row[\"orig_mi\"]\n",
    "    position = [int(pos.split(\"_\")[-1]) for pos in position_columns if row[pos] == 1]\n",
    "    if len(position) == 0:\n",
    "        continue\n",
    "    position = position[0]\n",
    "    knockdown_mut = row[\"knockdown_mut\"]\n",
    "    \n",
    "    single_mutation_dict[f\"{cell_line}_{miRNA}_{position}\"] = knockdown_mut\n",
    "\n",
    "single_wobble_dict = {}\n",
    "for i, row in single_wobbles.iterrows():\n",
    "    cell_line = row[\"cell_line\"]\n",
    "    miRNA = row[\"orig_mi\"]\n",
    "    position = [int(pos.split(\"_\")[-1]) for pos in position_columns if row[pos] == 2]\n",
    "    if len(position) == 0:\n",
    "        continue\n",
    "    position = position[0]\n",
    "    knockdown_mut = row[\"knockdown_mut\"]\n",
    "    \n",
    "    single_wobble_dict[f\"{cell_line}_{miRNA}_{position}\"] = knockdown_mut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in all_mutations.iterrows():\n",
    "    # get all mutation positions\n",
    "    positions_mut = []\n",
    "    for col in position_columns:\n",
    "        if row[col] == 1:\n",
    "            positions_mut.append(col.split(\"_\")[-1])\n",
    "    # get all wobble positions\n",
    "    positions_wobble = []\n",
    "    for col in position_columns:\n",
    "        if row[col] == 2:\n",
    "            positions_wobble.append(col.split(\"_\")[-1])\n",
    "    \n",
    "    # get the cell line and microRNA\n",
    "    cell_line = row[\"cell_line\"]\n",
    "    miRNA = row[\"orig_mi\"]\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "    # for each mutation and wobble, find the entry in single_mutations_cell_line that matches\n",
    "    knockdown_single = []\n",
    "    for position in positions_mut:\n",
    "        try:\n",
    "            knockdown_single.append(single_mutation_dict[f\"{cell_line}_{miRNA}_{position}\"])\n",
    "        except KeyError:\n",
    "            continue\n",
    "    for position in positions_wobble:\n",
    "        try:\n",
    "            knockdown_single.append(single_wobble_dict[f\"{cell_line}_{miRNA}_{position}\"])\n",
    "        except KeyError:\n",
    "            continue\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "    # MAXIMUM EFFECT\n",
    "    # get the mutation with the largest impact\n",
    "    # the data should be log10(stability) at this point, so the maximum is the mutation with the highest stability\n",
    "    if len(knockdown_single) > 0:\n",
    "        all_mutations.loc[index, \"knockdown_strongest\"] = max(knockdown_single)\n",
    "    else:\n",
    "        all_mutations.loc[index, \"knockdown_strongest\"] = np.nan\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "    if len(knockdown_single) == 0:\n",
    "        continue\n",
    "    \n",
    "    # for testing purposes\n",
    "    print_flag = False\n",
    "    if index == \"5.32_miRNA_miR-31-3p_smut_swob_omut16.18.19.21_owob14.17_JEG3\":\n",
    "        print_flag = True\n",
    "    \n",
    "    if print_flag:\n",
    "        print(row[\"knockdown_orig\"])\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "    # convert the original stability to a linear value\n",
    "    knockdown_orig = 10**row[\"knockdown_orig\"]\n",
    "    # if the stability is larger than 0.99, set it to 0.99)\n",
    "    knockdown_orig = knockdown_orig if knockdown_orig < 0.99 else 0.99\n",
    "    # convert to an actual knockdown value (minus one so that no change is 0)\n",
    "    knockdown_orig = (1/knockdown_orig)-1\n",
    "    if print_flag:\n",
    "        print(knockdown_orig)\n",
    "    \n",
    "    # convert the single mutations stabilities to a linear value\n",
    "    knockdown_single = [10**x for x in knockdown_single]\n",
    "    # if the stability is larger than 0.99, set it to 0.99)\n",
    "    knockdown_single = [x if x < 0.99 else 0.99 for x in knockdown_single]\n",
    "    # convert to an actual knockdown value (minus one so that no change is 0)\n",
    "    knockdown_single = [(1/x)-1 for x in knockdown_single]\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # at this point knockdown_single tells you how much the expression changes for each mutation\n",
    "    # we convert this a relative fold change compared to the original knockdown\n",
    "    knockdown_single = [x/knockdown_orig for x in knockdown_single]\n",
    "    \n",
    "    # if any of the resultant values is larger than 1, set it to 1\n",
    "    # the assumption is that the non-mutated microRNA is the most potent\n",
    "    # doing this can reduce noise and weird behavior in the following\n",
    "    knockdown_single = [x if x < 1 else 1 for x in knockdown_single]\n",
    "    \n",
    "    # we then invert this relationship such that we can sum or add the values\n",
    "    # multiple mutations increase the loss of activity\n",
    "    knockdown_single = [1/x for x in knockdown_single]\n",
    "    if print_flag:\n",
    "        print(knockdown_single)\n",
    "    \n",
    "    # calculate the aggregate using sum or product\n",
    "    # for the sum, if all values are 1, we want a sum of one\n",
    "    aggregate_knockdown_sum = np.sum(knockdown_single) - len(knockdown_single) + 1\n",
    "    aggregate_knockdown_product = np.product(knockdown_single)\n",
    "    if print_flag:\n",
    "        print(aggregate_knockdown_sum)\n",
    "    # invert the two again and multiply them by the original knockdown\n",
    "    aggregate_knockdown_sum = knockdown_orig/aggregate_knockdown_sum\n",
    "    aggregate_knockdown_product = knockdown_orig/aggregate_knockdown_product\n",
    "    \n",
    "    # convert the two back to log10 expression data\n",
    "    aggregate_knockdown_sum = np.log10(1/(aggregate_knockdown_sum+1))\n",
    "    aggregate_knockdown_product = np.log10(1/(aggregate_knockdown_product+1))\n",
    "    \n",
    "    all_mutations.loc[index, \"knockdown_aggregate_sum\"] = aggregate_knockdown_sum\n",
    "    all_mutations.loc[index, \"knockdown_aggregate_product\"] = aggregate_knockdown_product\n",
    "      \n",
    "# drop nan\n",
    "all_mutations = all_mutations.dropna(subset=[\"knockdown_strongest\"])\n",
    "all_mutations = all_mutations.dropna(subset=[\"knockdown_aggregate_sum\"])\n",
    "all_mutations = all_mutations.dropna(subset=[\"knockdown_aggregate_product\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2.4, 1.8))\n",
    "\n",
    "r2_single = stats.pearsonr(all_mutations[\"knockdown_strongest\"], all_mutations[\"knockdown_mut\"])[0]**2\n",
    "r2_agg_sum = stats.pearsonr(all_mutations[\"knockdown_aggregate_sum\"], all_mutations[\"knockdown_mut\"])[0]**2\n",
    "r2_agg_prod = stats.pearsonr(all_mutations[\"knockdown_aggregate_product\"], all_mutations[\"knockdown_mut\"])[0]**2\n",
    "\n",
    "plt.scatter(all_mutations[\"knockdown_strongest\"], all_mutations[\"knockdown_mut\"], s=1, color=\"blue\", label=\"maximum effect, r$^2$: \" + f\"{r2_single:.2f}\", rasterized=True)\n",
    "plt.scatter(all_mutations[\"knockdown_aggregate_sum\"], all_mutations[\"knockdown_mut\"], s=1, color=\"red\", label=\"sum of effects, r$^2$: \" + f\"{r2_agg_sum:.2f}\", rasterized=True)\n",
    "plt.scatter(all_mutations[\"knockdown_aggregate_product\"], all_mutations[\"knockdown_mut\"], s=1, color=\"green\", label=\"product of effects, r$^2$: \" + f\"{r2_agg_prod:.2f}\", rasterized=True)\n",
    "\n",
    "plt.plot([-1.5, 0], [-1.5, 0], linestyle=\"--\", color=\"black\")\n",
    "plt.xlabel(r\"log$_{10}$(stability predicted)\")\n",
    "plt.ylabel(r\"log$_{10}$(stability measured)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.legend(loc = [0.7, 0.0])\n",
    "for format in [\"png\", \"svg\"]:\n",
    "    plt.savefig(f\"{base_plot_folder}/5.3-heuristic_model.{format}\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the top 10 with the largest difference between predicted and measured for aggregate\n",
    "all_mutations[\"difference\"] = all_mutations[\"knockdown_aggregate_product\"] - all_mutations[\"knockdown_mut\"]\n",
    "all_mutations[\"abs_difference\"] = np.abs(all_mutations[\"difference\"])\n",
    "all_mutations_sorted = all_mutations.sort_values(\"abs_difference\", ascending=False)\n",
    "all_mutations_sorted.head(10)[[\"knockdown_mut\", \"knockdown_orig\", \"knockdown_aggregate_product\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.4 - Build a tree model to predict mutation impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframes\n",
    "output_folder = f\"../outputs/5_mutations\"\n",
    "\n",
    "# create it if it does not exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the training_df to the output_folder\n",
    "training_df.to_csv(f\"{output_folder}/5.4_training_df.csv\")\n",
    "training_df_confound.to_csv(f\"{output_folder}/5.4_training_df_confound.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training_df\n",
    "training_df = pd.read_csv(f\"{output_folder}/5.4_training_df.csv\", index_col=0)\n",
    "training_df_confound = pd.read_csv(f\"{output_folder}/5.4_training_df_confound.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the plot folder\n",
    "plot_folder = os.path.join(base_plot_folder, \"5.4_tree_models\")\n",
    "\n",
    "# create it if it does not exist\n",
    "if not os.path.exists(plot_folder):\n",
    "    os.makedirs(plot_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4.1 - Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the impact mutation count columns to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impact_columns = [\"no_high_impact\", \"no_mid_impact\", \"no_low_impact\", \"no_no_impact\"]\n",
    "\n",
    "# convert positions columns to categorical\n",
    "for col in impact_columns:\n",
    "    training_df[col] = training_df[col].astype(\"int\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split off a single mirna for testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df[\"orig_mi\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_training_df(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # save the original (we will need it later)\n",
    "    df[\"knockdown_orig_archive\"] = df[\"knockdown_orig\"]\n",
    "    df[\"knockdown_mut_archive\"] = df[\"knockdown_mut\"]\n",
    "\n",
    "    # make the data linear\n",
    "    df[\"knockdown_orig\"] = 10**df[\"knockdown_orig\"]\n",
    "    df[\"knockdown_mut\"] = 10**df[\"knockdown_mut\"]\n",
    "\n",
    "    # invert it\n",
    "    df[\"knockdown_mut\"] = 1/df[\"knockdown_mut\"]\n",
    "    df[\"knockdown_orig\"] = 1/df[\"knockdown_orig\"]\n",
    "\n",
    "    # normalize the knockdown values by the original knockdown\n",
    "    df[\"knockdown_mut\"] = (df[\"knockdown_mut\"]-1)/(df[\"knockdown_orig\"]-1)\n",
    "\n",
    "    # set values smaller than 0 to 0\n",
    "    df[\"knockdown_mut\"] = df[\"knockdown_mut\"].apply(lambda x: x if x > 0 else 0)\n",
    "    # set values larger than 1 to 1\n",
    "    df[\"knockdown_mut\"] = df[\"knockdown_mut\"].apply(lambda x: x if x < 1 else 1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = process_training_df(training_df)\n",
    "training_df_confound = process_training_df(training_df_confound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here, we exclude on of the miRNAs to later use it as test data\n",
    "excluded_mirna = \"hsa-miR-31-5p\"\n",
    "training_df_excluded = training_df[training_df[\"orig_mi\"] == excluded_mirna]\n",
    "training_df = training_df[training_df[\"orig_mi\"] != excluded_mirna]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter the data such that the original knockdown is reasonably high\n",
    "#### This is necessary for the ratio to be meaningful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the length of both\n",
    "print(len(training_df))\n",
    "print(len(training_df_excluded))\n",
    "\n",
    "# filter to those with \"knockdown_orig\" > 3 (same as we did above)\n",
    "# this is necessary to reduce noise\n",
    "training_df_filter = training_df[training_df[\"knockdown_orig\"] > 3]\n",
    "training_df_excluded_filter = training_df_excluded[training_df_excluded[\"knockdown_orig\"] > 3]\n",
    "\n",
    "print(len(training_df_filter))\n",
    "print(len(training_df_excluded_filter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we define what information we actually want to use for the training\n",
    "# The simplest way is to use the impact columns only and give no information about the original knockdown\n",
    "training_columns = impact_columns\n",
    "\n",
    "# define X and y columns\n",
    "X = training_df_filter[training_columns]\n",
    "y = training_df_filter[\"knockdown_mut\"]\n",
    "X_excluded = training_df_excluded_filter[training_columns]\n",
    "y_excluded = training_df_excluded_filter[\"knockdown_mut\"]\n",
    "\n",
    "# also save the original knockdown so that the data can be converted back to expression data later\n",
    "y_restore = training_df_filter[\"knockdown_orig\"]\n",
    "y_restore_excluded = training_df_excluded_filter[\"knockdown_orig\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename them to X_train, y_train, X_test, y_test\n",
    "X_train = X\n",
    "y_train = y\n",
    "\n",
    "X_test = X_excluded\n",
    "y_test = y_excluded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4.2 - Train an XGBoost tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [50, 100, 200, 500, 1000, 1500]\n",
    "max_depths = [5, 6, 7, 8, 9]\n",
    "learning_rates = [0.1, 0.2, 0.3]\n",
    "reg_lambdas = [1, 2, 3]\n",
    "\n",
    "total_combs = len(estimators)*len(max_depths)*len(learning_rates)*len(reg_lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "screen_params = pd.DataFrame(columns=[\"n_estimators\", \"max_depth\", \"learning_rate\", \"training_r2\", \"test_r2\"])\n",
    "\n",
    "i = 0\n",
    "for n_estimators, max_depth, learning_rate, reg_lambda in itertools.product(estimators, max_depths, learning_rates, reg_lambdas):\n",
    "    # create model instance\n",
    "    bst = xgb.XGBRegressor(n_estimators=n_estimators, max_depth=max_depth, learning_rate=learning_rate, enable_categorical=False, reg_lambda=reg_lambda)\n",
    "    # fit model\n",
    "    bst.fit(X_train, y_train)\n",
    "    # make predictions\n",
    "    preds_train = bst.predict(X_train)\n",
    "    preds_test = bst.predict(X_test)\n",
    "    \n",
    "    # restore the values fromn ratio to regular log10 expression\n",
    "    preds_train = np.log10(1/(((y_restore - 1) * preds_train) + 1))\n",
    "    preds_test = np.log10(1/(((y_restore_excluded - 1) * preds_test) + 1))\n",
    "    \n",
    "    y_train_restored = np.log10(1/(((y_restore - 1) * y_train) + 1))\n",
    "    y_test_restored = np.log10(1/(((y_restore_excluded - 1) * y_test) + 1))\n",
    "    \n",
    "    # calculate r2 and the mse\n",
    "    r2_train = stats.pearsonr(preds_train, y_train_restored)[0]**2\n",
    "    r2_test = stats.pearsonr(preds_test, y_test_restored)[0]**2\n",
    "    \n",
    "    mse_train = np.mean((preds_train - y_train_restored)**2)\n",
    "    mse_test = np.mean((preds_test - y_test_restored)**2)\n",
    "    \n",
    "    # add the new row to the screen_params dataframe\n",
    "    new_row = {\"n_estimators\": n_estimators, \"max_depth\": max_depth, \"learning_rate\": learning_rate,\n",
    "               \"reg_lambda\": reg_lambda, \"training_r2\": r2_train, \"test_r2\": r2_test,\n",
    "               \"mse_train\": mse_train, \"mse_test\": mse_test}\n",
    "    screen_params = pd.concat([screen_params, pd.DataFrame([new_row])])\n",
    "    \n",
    "    i += 1\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Progress: {i}/{total_combs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [\"n_estimators\", \"max_depth\", \"learning_rate\", \"reg_lambda\"]\n",
    "optimal_screen_params = screen_params.sort_values(\"mse_test\", ascending=True).head(1)\n",
    "print(optimal_screen_params)\n",
    "optimal_screen_params = dict(optimal_screen_params[parameters].iloc[0])\n",
    "\n",
    "bst = xgb.XGBRegressor(**optimal_screen_params)\n",
    "bst.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "preds_train = bst.predict(X_train)\n",
    "preds_test = bst.predict(X_test)\n",
    "\n",
    "# restore the values fromn ratio to regular log10 expression\n",
    "preds_train = np.log10(1/(((y_restore - 1) * preds_train) + 1))\n",
    "preds_test = np.log10(1/(((y_restore_excluded - 1) * preds_test) + 1))\n",
    "\n",
    "y_train_restored = np.log10(1/(((y_restore - 1) * y_train) + 1))\n",
    "y_test_restored = np.log10(1/(((y_restore_excluded - 1) * y_test) + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a log plot of the results (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2.4, 1.8))\n",
    "\n",
    "# calculate r2\n",
    "r2_test = stats.pearsonr(y_test_restored, preds_test)[0]**2\n",
    "r2_train = stats.pearsonr(y_train_restored, preds_train)[0]**2\n",
    "\n",
    "# plot predictions vs true values\n",
    "plt.scatter(y_train_restored, preds_train, color = \"blue\", s=2, label=\"train, r$^2$: \" + f\"{r2_train:.2f}\")\n",
    "plt.scatter(y_test_restored, preds_test, color = \"red\", s=2, label=f\"test, r$^2$: \" + f\"{r2_test:.2f}\\n({excluded_mirna})\")\n",
    "\n",
    "# plot a line for x=y\n",
    "plt.plot([-1.8, 0], [-1.8, 0], color=\"black\", linestyle=\"--\", linewidth=2)\n",
    "\n",
    "plt.xlabel(r\"log$_{10}$(measured stability)\")\n",
    "plt.ylabel(r\"log$_{10}$(predicted stability)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.legend(loc = [1,0.5], fontsize=7)\n",
    "plt.savefig(f\"{plot_folder}/5.4.2-XGBoost_{excluded_mirna}.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict on the entire data (minus the non-mutated miRNAs!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df_wo_nonmut = training_df.copy()\n",
    "training_df_wo_nonmut_excluded = training_df_excluded.copy()\n",
    "\n",
    "# exclude original mirnas\n",
    "training_df_wo_nonmut = training_df_wo_nonmut[~training_df_wo_nonmut.index.str.contains(\"5.0_\")]\n",
    "training_df_wo_nonmut_excluded = training_df_wo_nonmut_excluded[~training_df_wo_nonmut_excluded.index.str.contains(\"5.0_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and y columns\n",
    "X = training_df_wo_nonmut[training_columns]\n",
    "y = training_df_wo_nonmut[\"knockdown_mut_archive\"]\n",
    "X_excluded = training_df_wo_nonmut_excluded[training_columns]\n",
    "y_excluded = training_df_wo_nonmut_excluded[\"knockdown_mut_archive\"]\n",
    "\n",
    "# also save the original knockdown so that the data can be converted back to expression data later\n",
    "y_restore_full = training_df_wo_nonmut[\"knockdown_orig\"]\n",
    "y_restore_excluded_full = training_df_wo_nonmut_excluded[\"knockdown_orig\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "preds_train = bst.predict(X)\n",
    "preds_test = bst.predict(X_excluded)\n",
    "\n",
    "# restore the values fromn ratio to regular log10 expression\n",
    "preds_train = np.log10(1/(((y_restore_full - 1) * preds_train) + 1))\n",
    "preds_test = np.log10(1/(((y_restore_excluded_full - 1) * preds_test) + 1))\n",
    "\n",
    "# y_train_restored = np.log10(1/(((y_restore_full - 1) * y) + 1))\n",
    "# y_test_restored = np.log10(1/(((y_restore_excluded_full - 1) * y_excluded) + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save these \n",
    "preds_train_xgboost = preds_train.copy()\n",
    "preds_test_xgboost = preds_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2.4, 1.8))\n",
    "\n",
    "# calculate r2\n",
    "r2_test = stats.pearsonr(y_excluded, preds_test)[0]**2\n",
    "r2_train = stats.pearsonr(y, preds_train)[0]**2\n",
    "\n",
    "# plot predictions vs true values\n",
    "plt.scatter(y, preds_train, color = \"blue\", s=2, label=\"train, r$^2$: \" + f\"{r2_train:.2f}\", rasterized=True)\n",
    "plt.scatter(y_excluded, preds_test, color = \"red\", s=2, label=f\"test, r$^2$: \" + f\"{r2_test:.2f}\\n({excluded_mirna})\", rasterized=True)\n",
    "\n",
    "# plot a line for x=y\n",
    "plt.plot([-1.8, 0], [-1.8, 0], color=\"black\", linestyle=\"--\", linewidth=2)\n",
    "\n",
    "plt.xlabel(r\"log$_{10}$(measured stability)\")\n",
    "plt.ylabel(r\"log$_{10}$(predicted stability)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.legend(loc = [1,0.5], fontsize=7)\n",
    "plt.savefig(f\"{plot_folder}/5.4.2-XGBoost{excluded_mirna}_full.png\", dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4.3 Train a single regression tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import itertools\n",
    "\n",
    "max_depths = [5, 6, 7, 8, 9, 10]\n",
    "min_samples_splits = [2, 3, 5, 10]\n",
    "min_samples_leafs = [1, 2, 3, 4]\n",
    "max_leaf_nodes = [None, 10, 20, 100]  # None means unlimited\n",
    "total_combs = len(max_depths)*len(min_samples_splits)*len(min_samples_leafs)*len(max_leaf_nodes)\n",
    "\n",
    "# DataFrame to store the results\n",
    "screen_params = pd.DataFrame(columns=[\n",
    "    \"max_depth\", \"min_samples_split\", \"min_samples_leaf\", \"max_leaf_nodes\",\n",
    "    \"training_r2\", \"test_r2\", \"mse_train\", \"mse_test\"\n",
    "])\n",
    "\n",
    "i = 0\n",
    "# Iterating over the parameter grid\n",
    "for max_depth, min_samples_split, min_samples_leaf, max_leaf_node in itertools.product(\n",
    "    max_depths, min_samples_splits, min_samples_leafs, max_leaf_nodes):\n",
    "    \n",
    "    # Create the model with current parameter combination\n",
    "    tree = DecisionTreeRegressor(max_depth=max_depth, min_samples_split=min_samples_split,\n",
    "                                 min_samples_leaf=min_samples_leaf, max_leaf_nodes=max_leaf_node,\n",
    "                                 criterion=\"squared_error\")\n",
    "    \n",
    "    # Fit model\n",
    "    tree.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    preds_train = tree.predict(X_train)\n",
    "    preds_test = tree.predict(X_test)\n",
    "    \n",
    "    # restore the values fromn ratio to regular log10 expression\n",
    "    preds_train = np.log10(1/(((y_restore - 1) * preds_train) + 1))\n",
    "    preds_test = np.log10(1/(((y_restore_excluded - 1) * preds_test) + 1))\n",
    "    \n",
    "    y_train_restored = np.log10(1/(((y_restore - 1) * y_train) + 1))\n",
    "    y_test_restored = np.log10(1/(((y_restore_excluded - 1) * y_test) + 1))\n",
    "    \n",
    "    # Calculate R^2 and MSE\n",
    "    r2_train = r2_score(y_train_restored, preds_train)\n",
    "    r2_test = r2_score(y_test_restored, preds_test)\n",
    "    mse_train = mean_squared_error(y_train_restored, preds_train)\n",
    "    mse_test = mean_squared_error(y_test_restored, preds_test)\n",
    "    \n",
    "    # Append the results to the DataFrame\n",
    "    new_row = {\n",
    "        \"max_depth\": max_depth, \"min_samples_split\": min_samples_split,\n",
    "        \"min_samples_leaf\": min_samples_leaf, \"max_leaf_nodes\": max_leaf_node,\n",
    "        \"training_r2\": r2_train, \"test_r2\": r2_test,\n",
    "        \"mse_train\": mse_train, \"mse_test\": mse_test,\n",
    "        \"total_leaf_nodes\": tree.get_n_leaves()\n",
    "    }\n",
    "    screen_params = pd.concat([screen_params, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    \n",
    "    i += 1\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Progress: {i}/{total_combs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [\"max_depth\", \"min_samples_split\", \"min_samples_leaf\", \"max_leaf_nodes\"]\n",
    "# add 0.01 * max_leaf_nodes to the mse_test to penalize large trees\n",
    "screen_params_mse = screen_params.copy()\n",
    "screen_params_mse[\"mse_test\"] = screen_params_mse[\"mse_test\"] + 0.0001 * screen_params_mse[\"max_leaf_nodes\"]\n",
    "optimal_screen_params = screen_params_mse.sort_values(\"mse_test\", ascending=True).head(10)\n",
    "print(optimal_screen_params)\n",
    "optimal_screen_params = dict(optimal_screen_params[parameters].iloc[0])\n",
    "\n",
    "# Create model instance\n",
    "tree = DecisionTreeRegressor(**optimal_screen_params, criterion=\"squared_error\")\n",
    "\n",
    "# Fit model\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "preds_train = tree.predict(X_train)\n",
    "preds_test = tree.predict(X_test)\n",
    "\n",
    "# restore the values fromn ratio to regular log10 expression\n",
    "preds_train = np.log10(1/(((y_restore - 1) * preds_train) + 1))\n",
    "preds_test = np.log10(1/(((y_restore_excluded - 1) * preds_test) + 1))\n",
    "\n",
    "y_train_restored = np.log10(1/(((y_restore - 1) * y_train) + 1))\n",
    "y_test_restored = np.log10(1/(((y_restore_excluded - 1) * y_test) + 1))\n",
    "\n",
    "# Calculate R^2 and MSE\n",
    "r2_train = r2_score(y_train_restored, preds_train)\n",
    "r2_test = r2_score(y_test_restored, preds_test)\n",
    "mse_train = mean_squared_error(y_train_restored, preds_train)\n",
    "mse_test = mean_squared_error(y_test_restored, preds_test)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Training R^2: {r2_train:.4f}\")\n",
    "print(f\"Test R^2: {r2_test:.4f}\")\n",
    "print(f\"Training MSE: {mse_train:.4f}\")\n",
    "print(f\"Test MSE: {mse_test:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "screen_params.sort_values(\"mse_test\", ascending=True).to_csv(f\"{output_folder}/5.4_tree_models_screen_params.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "\n",
    "plt.figure(figsize=(9,2.4))\n",
    "\n",
    "nodes = plot_tree(tree, filled=True, feature_names=list(X_train.columns), rounded=True)\n",
    "\n",
    "# Process the nodes to adjust labels\n",
    "for node in nodes:\n",
    "    node.set_fontsize(7)\n",
    "    lines = node.get_text().split('\\n')\n",
    "    # If the node is a leaf\n",
    "    if len(lines) > 3:\n",
    "        text = lines[0]\n",
    "        text = text.split(\"_\")\n",
    "        text[0] = \"#\"\n",
    "        text = \" \".join(text)\n",
    "        node.set_text(text)\n",
    "    else:\n",
    "        node.set_text(lines[-1].split('value = ')[1])\n",
    "\n",
    "# plot_tree(tree, filled=True, feature_names=X_train.columns, rounded=True)\n",
    "for format in [\"png\", \"svg\"]:\n",
    "    plt.savefig(f\"{plot_folder}/5.4.3 - decision_tree.{format}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model to a file\n",
    "filename = '5.4.3_decision_tree_model.joblib'\n",
    "filepath = os.path.join(output_folder, filename)\n",
    "joblib.dump(tree, filepath)\n",
    "\n",
    "print(f\"Model saved to {filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a log plot of the results (regression tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2.4, 1.8))\n",
    "\n",
    "# calculate r2\n",
    "r2_test = stats.pearsonr(y_test_restored, preds_test)[0]**2\n",
    "r2_train = stats.pearsonr(y_train_restored, preds_train)[0]**2\n",
    "\n",
    "# plot predictions vs true values\n",
    "plt.scatter(y_train_restored, preds_train, color = \"blue\", s=2, label=\"train, r$^2$: \" + f\"{r2_train:.2f}\")\n",
    "plt.scatter(y_test_restored, preds_test, color = \"red\", s=2, label=f\"test, r$^2$: \" + f\"{r2_test:.2f}\\n({excluded_mirna})\")\n",
    "\n",
    "# plot a line for x=y\n",
    "plt.plot([-1.8, 0], [-1.8, 0], color=\"black\", linestyle=\"--\", linewidth=2)\n",
    "\n",
    "plt.xlabel(r\"log$_{10}$(measured stability)\")\n",
    "plt.ylabel(r\"log$_{10}$(predicted stability)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.legend(loc = [1,0.5], fontsize=7)\n",
    "plt.savefig(f\"{plot_folder}/5.4.3-RegressionTree_{excluded_mirna}.png\", dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict on the entire data (regression tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df_wo_nonmut = training_df.copy()\n",
    "training_df_wo_nonmut_excluded = training_df_excluded.copy()\n",
    "training_df_confound_wo_nonmut = training_df_confound.copy()\n",
    "\n",
    "# exclude original mirnas\n",
    "training_df_wo_nonmut = training_df_wo_nonmut[~training_df_wo_nonmut.index.str.contains(\"5.0_\")]\n",
    "training_df_wo_nonmut_excluded = training_df_wo_nonmut_excluded[~training_df_wo_nonmut_excluded.index.str.contains(\"5.0_\")]\n",
    "training_df_confound_wo_nonmut = training_df_confound_wo_nonmut[~training_df_confound_wo_nonmut.index.str.contains(\"5.0_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and y columns\n",
    "X = training_df_wo_nonmut[training_columns]\n",
    "y = training_df_wo_nonmut[\"knockdown_mut_archive\"]\n",
    "X_excluded = training_df_wo_nonmut_excluded[training_columns]\n",
    "y_excluded = training_df_wo_nonmut_excluded[\"knockdown_mut_archive\"]\n",
    "X_confound = training_df_confound_wo_nonmut[training_columns]\n",
    "y_confound = training_df_confound_wo_nonmut[\"knockdown_mut_archive\"]\n",
    "\n",
    "# also save the original knockdown so that the data can be converted back to expression data later\n",
    "y_restore_full = training_df_wo_nonmut[\"knockdown_orig\"]\n",
    "y_restore_excluded_full = training_df_wo_nonmut_excluded[\"knockdown_orig\"]\n",
    "y_restore_confound = training_df_confound_wo_nonmut[\"knockdown_orig\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_index_array = np.array(training_df.index)\n",
    "\n",
    "# find the numerical indices (.iloc) of anything with orig_mi hsa-miR-21-5p\n",
    "indices_21 = training_df_wo_nonmut[training_df_wo_nonmut[\"orig_mi\"] == \"hsa-miR-21-5p\"].index\n",
    "# Find the positions of your specific indices in the DataFrame's index array\n",
    "positions_21 = np.where(np.isin(df_index_array, indices_21))\n",
    "\n",
    "# find the numerical indices (.iloc)of anything with orig_mi hsa-miR-19b-3p\n",
    "indices_19 = training_df_wo_nonmut[training_df_wo_nonmut[\"orig_mi\"] == \"hsa-miR-19b-3p\"].index\n",
    "# Find the positions of your specific indices in the DataFrame's index array\n",
    "positions_19 = np.where(np.isin(df_index_array, indices_21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "preds_train = tree.predict(X)\n",
    "preds_test = tree.predict(X_excluded)\n",
    "preds_confound = tree.predict(X_confound)\n",
    "\n",
    "# restore the values fromn ratio to regular log10 expression\n",
    "preds_train = np.log10(1/(((y_restore_full - 1) * preds_train) + 1))\n",
    "preds_test = np.log10(1/(((y_restore_excluded_full - 1) * preds_test) + 1))\n",
    "preds_confound = np.log10(1/(((y_restore_confound - 1) * preds_confound) + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2.4, 1.8))\n",
    "\n",
    "# calculate r2\n",
    "r2_test = stats.pearsonr(y_excluded, preds_test)[0]**2\n",
    "r2_train = stats.pearsonr(y, preds_train)[0]**2\n",
    "\n",
    "# plot predictions vs true values\n",
    "plt.scatter(y, preds_train, color = \"tab:blue\", s=2, label=\"train, r$^2$: \" + f\"{r2_train:.2f}\", rasterized=True)\n",
    "plt.scatter(y_excluded, preds_test, color = \"tab:red\", s=2, label=f\"test, r$^2$: \" + f\"{r2_test:.2f}\", rasterized=True) #\\n({excluded_mirna})\"\n",
    "\n",
    "# plot a line for x=y\n",
    "plt.plot([-1.8, 0], [-1.8, 0], color=\"black\", linestyle=\"--\", linewidth=2)\n",
    "\n",
    "plt.xlabel(r\"log$_{10}$(meas. stability)\")\n",
    "plt.ylabel(r\"log$_{10}$(pred. stability)\")\n",
    "plt.xticks([-1.5, -1, -0.5, 0])\n",
    "plt.yticks([-1.5, -1, -0.5, 0])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.legend(loc = [0.7,0.0], fontsize=7)\n",
    "for format in [\"png\", \"svg\"]:\n",
    "    plt.savefig(f\"{plot_folder}/5.4.3-RegressionTree_{excluded_mirna}_full.{format}\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2.4, 1.8))\n",
    "\n",
    "# plot predictions vs true values\n",
    "# plt.scatter(y, preds_train, color = \"blue\", s=5, label=\"train\")\n",
    "plt.scatter(y[indices_21], preds_train[indices_21], color = \"tab:red\", s=2, label=\"miR-21-5p\", rasterized=True)\n",
    "plt.scatter(y[indices_19], preds_train[indices_19], color = \"tab:cyan\", s=2, label=\"miR-19b-3p\", rasterized=True)\n",
    "\n",
    "# plot a line for x=y\n",
    "plt.plot([-1.8, 0], [-1.8, 0], color=\"black\", linestyle=\"--\", linewidth=2)\n",
    "\n",
    "plt.xlabel(r\"log$_{10}$(meas. stability)\")\n",
    "plt.ylabel(r\"log$_{10}$(pred. stability)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.legend(loc = [0.7,0.0], fontsize=7)\n",
    "for format in [\"png\", \"svg\"]:\n",
    "    plt.savefig(f\"{plot_folder}/5.4.3-RegressionTree_highlighted_individuality.{format}\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2.4, 1.8))\n",
    "\n",
    "# calculate r2\n",
    "r2_confound = stats.pearsonr(y_confound, preds_confound)[0]**2\n",
    "r2_train = stats.pearsonr(y, preds_train)[0]**2\n",
    "\n",
    "# plot predictions vs true values\n",
    "plt.scatter(y, preds_train, color = \"tab:blue\", s=2, label=\"train, r$^2$: \" + f\"{r2_train:.2f}\", rasterized=True)\n",
    "plt.scatter(y_confound, preds_confound, color = \"tab:red\", s=2, label=f\"let-7, r$^2$: \" + f\"{r2_confound:.2f}\", rasterized=True) #\\n({excluded_mirna})\"\n",
    "\n",
    "# plot a line for x=y\n",
    "plt.plot([-1.8, 0], [-1.8, 0], color=\"black\", linestyle=\"--\", linewidth=2)\n",
    "\n",
    "plt.xlabel(r\"log$_{10}$(meas. stability)\")\n",
    "plt.ylabel(r\"log$_{10}$(pred. stability)\")\n",
    "plt.xticks([-1.5, -1, -0.5, 0])\n",
    "plt.yticks([-1.5, -1, -0.5, 0])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.legend(loc = [0.7,0.0], fontsize=7)\n",
    "for format in [\"png\", \"svg\"]:\n",
    "    plt.savefig(f\"{plot_folder}/5.4.3-RegressionTree_let7_full.{format}\", dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare XGBoost and Regression Tree predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2.4, 1.8))\n",
    "plt.scatter(preds_train, preds_train_xgboost)\n",
    "plt.scatter(preds_test, preds_test_xgboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.5 - Predict on miRbase miRNAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, get all relevant microRNAs, either those in high confidence in mirbase or those in mirgenedb\n",
    "with open(\"../microrna_data/likely_real_mirnas.pkl\", \"rb\") as f:\n",
    "    relevant_mirna_list = pickle.load(f)\n",
    "    \n",
    "# load the regression tree\n",
    "filename = '5.4.3_decision_tree_model.joblib'\n",
    "filepath = os.path.join(output_folder, filename)\n",
    "tree = joblib.load(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mirbase_all_relevant = mirbase.loc[relevant_mirna_list, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mirna_length = 21\n",
    "position_columns = [\"pos_\" + str(i) for i in range(1, mirna_length+1)]\n",
    "impact_columns = [\"no_high_impact\", \"no_mid_impact\", \"no_low_impact\", \"no_no_impact\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DO NOT RUN THIS CODE EVERY TIME - TAKES AROUND 43 MIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This crosstalk dict gives the crosstalk for a specific target site (miRNA x) for all other miRNAs y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in mirbase.iterrows():\n",
    "    if index == \"hsa-let-7b-5p\":\n",
    "        # create the dataframe\n",
    "        df = pd.DataFrame(columns=position_columns, index=mirbase_all_relevant.index)\n",
    "        target = row[\"target\"]\n",
    "        \n",
    "        # add position-wise mutation info\n",
    "        for mirna_index, mirna_row in mirbase_all_relevant.iterrows():\n",
    "            mirna_seq = mirna_row[\"sequence_norm\"]\n",
    "            pattern = extract_pattern_from_seq(target=target, mirna=mirna_seq)\n",
    "            df.loc[mirna_index, position_columns] = pattern\n",
    "            \n",
    "        # summarize mutation impact\n",
    "        df = get_median_mut_classification(df, mutation_impact_df)\n",
    "        \n",
    "        # convert positions columns to categorical\n",
    "        for col in impact_columns:\n",
    "            df[col] = df[col].astype(\"int\")\n",
    "        \n",
    "        # use the tree to predict crosstalk\n",
    "        X = df[impact_columns]\n",
    "        predictions = tree.predict(X)\n",
    "        df[\"crosstalk\"] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_family_mirnas(family):\n",
    "    return mirbase[mirbase['family_extended'] == family].index.to_list()\n",
    "\n",
    "let7_family = get_family_mirnas(\"let-7-5p\")\n",
    "\n",
    "df.loc[let7_family, \"crosstalk\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_crosstalk_dict = {}\n",
    "for index, row in mirbase.iterrows():\n",
    "    # create the dataframe\n",
    "    df = pd.DataFrame(columns=position_columns, index=mirbase_all_relevant.index)\n",
    "    target = row[\"target\"]\n",
    "    \n",
    "    # add position-wise mutation info\n",
    "    for mirna_index, mirna_row in mirbase_all_relevant.iterrows():\n",
    "        mirna_seq = mirna_row[\"sequence_norm\"]\n",
    "        pattern = extract_pattern_from_seq(target=target, mirna=mirna_seq)\n",
    "        df.loc[mirna_index, position_columns] = pattern\n",
    "        \n",
    "    # summarize mutation impact\n",
    "    df = get_median_mut_classification(df, mutation_impact_df)\n",
    "    \n",
    "    # convert positions columns to categorical\n",
    "    for col in impact_columns:\n",
    "        df[col] = df[col].astype(\"int\")\n",
    "    \n",
    "    # use the tree to predict crosstalk\n",
    "    X = df[impact_columns]\n",
    "    predictions = tree.predict(X)\n",
    "    df[\"crosstalk\"] = predictions\n",
    "    \n",
    "    # save to dict\n",
    "    full_crosstalk_dict[index] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the crosstalk dict to a file\n",
    "output_folder = \"../outputs/5_mutations\"\n",
    "\n",
    "with open(f\"{output_folder}/5.5_full_crosstalk_dict.pkl\", \"wb\") as f:\n",
    "    pickle.dump(full_crosstalk_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.7 - Crosstalk filtering for Notebook 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_folder = os.path.join(base_plot_folder, \"5.7_crosstalk_filtering\")\n",
    "# create folder if it doesn't exist\n",
    "if not os.path.exists(plot_folder):\n",
    "    os.makedirs(plot_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from library2_utils.transfer_functions import transfer_function\n",
    "\n",
    "with open(f\"../outputs/3_fitting/combined_dataset/combined_dataset_popt_wo_crosstalk.pkl\", \"rb\") as f:\n",
    "    popt = pickle.load(f)\n",
    "with open(f\"../outputs/3_fitting/combined_dataset/combined_dataset_scale_dict_wo_crosstalk.pkl\", \"rb\") as f:\n",
    "    scale_dict = pickle.load(f)\n",
    "\n",
    "x_range_log = np.arange(0, 5.5, 0.1)\n",
    "x_range_lin = 10**x_range_log    \n",
    "y_transfer = np.log10(transfer_function(x_range_lin, *popt))\n",
    "\n",
    "df_expression = df_combined.copy()\n",
    "cell_lines_expression = [\"HEK293T\", \"HeLa\", \"MCF7\", \"A549\", \"HaCaT\", \"HUH7\", \"PC3\", \"JEG3\", \"Tera1\", \"SKNSH\"]\n",
    "\n",
    "# add the scale to the data\n",
    "for cell_line in cell_lines_expression:\n",
    "    df_expression[cell_line] = df_expression[cell_line] + scale_dict[cell_line] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate heuristically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = f\"../outputs/5_mutations\"\n",
    "\n",
    "# load full_crosstalk_dict\n",
    "with open(f\"{output_folder}/5.5_full_crosstalk_dict.pkl\", \"rb\") as f:\n",
    "    full_crosstalk_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from library2_utils.crosstalk import merge_identical_mirnas\n",
    "\n",
    "df_expression_orig = df_expression.copy()\n",
    "df_expression, groups = merge_identical_mirnas(df_expression, mirbase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_knockdown_predicted = np.log10((10**df_expression).apply(lambda x: transfer_function(x, *popt)))   \n",
    "\n",
    "crosstalk_filter_df = pd.DataFrame(columns=cell_lines_expression, index=df_expression.index)\n",
    "crosstalk_filter_df.loc[:, :] = False\n",
    "\n",
    "for key in full_crosstalk_dict.keys():\n",
    "    if not key in df_knockdown_predicted.index:\n",
    "        continue\n",
    "    \n",
    "    df = full_crosstalk_dict[key].copy()\n",
    "    df = df[df.index != key]\n",
    "    \n",
    "    # check for total less than 5 mutations\n",
    "    df = df[(df[\"no_total_impact\"]) < 5]\n",
    "    \n",
    "    # check for high impact mutations\n",
    "    df = df[df[\"no_high_impact\"] < 2]\n",
    "    \n",
    "    # check for mid_impact mutations\n",
    "    df = df[(df[\"no_mid_impact\"]+df[\"no_high_impact\"]) < 4]\n",
    "    \n",
    "    # check for all mutations\n",
    "    df = df[(df[\"no_low_impact\"]+df[\"no_mid_impact\"]+df[\"no_high_impact\"]) < 5]\n",
    "\n",
    "    # add an expression row to the df\n",
    "    df = df[df.index.isin(df_knockdown_predicted.index)]\n",
    "    \n",
    "    if len(df) > 0:\n",
    "        df.loc[:, cell_lines_expression] = df_knockdown_predicted.loc[df.index, cell_lines_expression]\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    # this is the knockdown across all remaining miRNAs after identifying those with likely crosstalk\n",
    "    min_by_cell_line = df[cell_lines_expression].min(axis=0)\n",
    "    \n",
    "    # this is the expected knockdown for the miRNA itself\n",
    "    knockdown_orig = df_knockdown_predicted.loc[key, cell_lines_expression]\n",
    "    \n",
    "    # we only filter if there is substantial expression of at least one of the potentially crosstalking miRNAs\n",
    "    crosstalk_filter_df.loc[key, :] = ((10**knockdown_orig)/3 > 10**min_by_cell_line) & (min_by_cell_line < -0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosstalk_filter_dict = {}\n",
    "for cell_line in cell_lines_expression:\n",
    "    crosstalk_filter_dict[cell_line] = list(crosstalk_filter_df[crosstalk_filter_df[cell_line] == True].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot crosstalk filtering to check if it makes sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are substantially shifted to the right\n",
    "ratio = 10**df_expression / 10**df_expression_orig\n",
    "ratio = ratio > 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2,1.5))\n",
    "x_range_log = np.linspace(0, 5.5, 1000)\n",
    "y_transfer = np.log10(transfer_function(10**x_range_log, *popt))\n",
    "\n",
    "x_vals = []\n",
    "y_vals = []\n",
    "for i, cell_line in enumerate(df_expression.columns):\n",
    "    df_ex = df_expression.loc[:, cell_line]\n",
    "    df_knock = df_knockdown.loc[:, cell_line]\n",
    "    \n",
    "    # grab miRNA classification\n",
    "    crosstalk_mirnas = crosstalk_filter_dict[cell_line]\n",
    "    \n",
    "    # filter crosstalk_mirnas to those in df_ex\n",
    "    crosstalk_mirnas = [mirna for mirna in crosstalk_mirnas if mirna in df_ex.index]\n",
    "    shifted_mirnas = ratio[cell_line][ratio[cell_line] == True].index\n",
    "    all_other_mirnas = df_ex.index.difference(crosstalk_mirnas).difference(shifted_mirnas)\n",
    "    \n",
    "    plt.scatter(df_ex.loc[all_other_mirnas], df_knock.loc[all_other_mirnas], s=4, alpha=0.4, edgecolor=\"none\",\n",
    "                color=\"tab:blue\", zorder=1, rasterized=True)\n",
    "    plt.scatter(df_ex.loc[crosstalk_mirnas],\n",
    "                df_knock.loc[crosstalk_mirnas], color=\"tab:red\", s=4, zorder=2, edgecolor=\"none\",\n",
    "                label=\"filtered crosstalk\" if i==0 else \"\", rasterized=True)\n",
    "    plt.scatter(df_ex.loc[shifted_mirnas],\n",
    "                df_knock.loc[shifted_mirnas], color=\"tab:orange\", s=4, zorder=3, edgecolor=\"none\",\n",
    "                label=\"merged miRNAs\" if i==0 else \"\", rasterized=True)\n",
    "    \n",
    "    x_vals.extend(np.log10(transfer_function(10**df_ex.loc[all_other_mirnas], *popt)))\n",
    "    y_vals.extend(df_knock.loc[all_other_mirnas])\n",
    "    \n",
    "    if i == 0:\n",
    "        plt.plot(x_range_log, y_transfer, ls=\"--\", lw=1, color=\"black\")\n",
    "\n",
    "x_vals_flatten = np.array(x_vals).flatten()\n",
    "y_vals_flatten = np.array(y_vals).flatten()\n",
    "r2 = stats.pearsonr(x_vals_flatten, y_vals_flatten)[0]**2\n",
    "rmsd = np.sqrt(np.mean((x_vals_flatten - y_vals_flatten)**2))\n",
    "\n",
    "#plt.title(f\"r$^2$: {r2:.4f}, RMSD: {rmsd:.4f}\")\n",
    "\n",
    "plt.xlabel(r\"log$_{10}$\"+f\"(miRNA expression)\")\n",
    "plt.ylabel(r\"log$_{10}$(stability)\")\n",
    "\n",
    "plt.xlim(0, 5.5)\n",
    "plt.xticks([1,2,3,4,5])\n",
    "plt.yticks([-2,-1,0])\n",
    "plt.ylim(-2, 0.25)\n",
    "plt.tight_layout()\n",
    "plt.legend(loc=\"lower left\", frameon=False, fontsize=7)\n",
    "for format in [\"png\", \"svg\"]:\n",
    "    plt.savefig(os.path.join(plot_folder, f\"5.7_crosstalk_filtering.{format}\"), dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2,1.5))\n",
    "x_range_log = np.linspace(0, 5.5, 1000)\n",
    "y_transfer = np.log10(transfer_function(10**x_range_log, *popt))\n",
    "\n",
    "x_vals = []\n",
    "y_vals = []\n",
    "for i, cell_line in enumerate(df_expression.columns):\n",
    "    df_ex = df_expression.loc[:, cell_line]\n",
    "    df_ex_orig = df_expression_orig.loc[:, cell_line]\n",
    "    df_knock = df_knockdown.loc[:, cell_line]\n",
    "    \n",
    "    # filter crosstalk_mirnas to those in df_ex\n",
    "    shifted_mirnas = ratio[cell_line][ratio[cell_line] == True].index\n",
    "    \n",
    "    plt.scatter(df_ex_orig.loc[shifted_mirnas],\n",
    "                df_knock.loc[shifted_mirnas], color=\"tab:blue\", s=4, zorder=2, edgecolor=\"none\",\n",
    "                label=\"before merging\" if i==0 else \"\", rasterized=True)\n",
    "    plt.scatter(df_ex.loc[shifted_mirnas],\n",
    "                df_knock.loc[shifted_mirnas], color=\"tab:orange\", s=4, zorder=3, edgecolor=\"none\",\n",
    "                label=\"after merging\" if i==0 else \"\", rasterized=True)\n",
    "    # add text to the points\n",
    "    # for mirna in shifted_mirnas:\n",
    "    #     if \"23b\" in mirna:\n",
    "    #         plt.text(df_ex.loc[mirna], df_knock.loc[mirna], \"-\".join(mirna.split(\"-\")[2:]), fontsize=4, color=\"black\")\n",
    "    \n",
    "    if i == 0:\n",
    "        plt.plot(x_range_log, y_transfer, ls=\"--\", lw=1, color=\"black\")\n",
    "\n",
    "plt.xlabel(r\"log$_{10}$\"+f\"(miRNA expression)\")\n",
    "plt.ylabel(r\"log$_{10}$(stability)\")\n",
    "\n",
    "plt.xlim(0, 5.5)\n",
    "plt.xticks([1,2,3,4,5])\n",
    "plt.yticks([-2,-1,0])\n",
    "plt.ylim(-2, 0.25)\n",
    "plt.tight_layout()\n",
    "plt.legend(loc=\"lower left\", frameon=False, fontsize=7)\n",
    "for format in [\"png\", \"svg\"]:\n",
    "    plt.savefig(os.path.join(plot_folder, f\"5.7_shifted_mirnas.{format}\"), dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the crosstalk dict to a file\n",
    "output_folder = \"../outputs/5_mutations\"\n",
    "\n",
    "with open(f\"{output_folder}/5.7_crosstalk_filter_dict.pkl\", \"wb\") as f:\n",
    "    pickle.dump(crosstalk_filter_dict, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
