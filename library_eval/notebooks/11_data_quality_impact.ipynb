{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import scipy.optimize as opt\n",
    "import itertools\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import pickle\n",
    "from library2_utils.color_scheme import cell_line_colors, cell_line_symbols\n",
    "from library2_utils.design_utilities import tsi\n",
    "\n",
    "# set the font size\n",
    "plt.rcParams.update({'font.size': 7})\n",
    "# set Helvetica globally\n",
    "plt.rcParams['font.family'] = 'Helvetica'\n",
    "\n",
    "# only use cell lines for which I have a substantial amount of data from different sources\n",
    "cell_lines_measured = [\"HEK293T\", \"HeLa\", \"SKNSH\", \"MCF7\", \"A549\", \"PC3\"]\n",
    "\n",
    "plot_folder = \"../plots/11_data_quality\"\n",
    "if not os.path.exists(plot_folder):\n",
    "    os.makedirs(plot_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook compares different datasets. The links to the individual datasets are given in the Supplementary Tables. The data needs to be downloaded and processed in order to run this Notebook. If that proves challenging, feel free to contact me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_expr_df_to_rpm(df):\n",
    "    # normalize\n",
    "    df = df.div(df.sum(axis=0), axis=1) * 1000000\n",
    "    # deduct the minimum and add one to the expression data to avoid division by 0\n",
    "    df = df - df.min() + 1\n",
    "    # normalize to rpm\n",
    "    df = df.div(df.sum(axis=0), axis=1) * 1000000\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load stability data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_input = \"../measured_data/2_normalized_log10\"\n",
    "\n",
    "# get the name of all files in \"reference\" folder\n",
    "reference_files = os.listdir(data_dir_input)\n",
    "\n",
    "# read them into a dictionary\n",
    "reference_dict = {}\n",
    "for reference_file in reference_files:\n",
    "    if reference_file.endswith(\".csv\"):\n",
    "        reference_dict[reference_file.split('.')[0]] = pd.read_csv(os.path.join(data_dir_input, reference_file), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all dfs that contain \"single\" in their key\n",
    "single_dfs = {key: reference_dict[key].copy() for key in reference_dict.keys() if \"full_single_high_conf\" in key or \"full_repeat\" in key}\n",
    "\n",
    "for key, df in single_dfs.items():\n",
    "    df.set_index(\"miRNA1\", inplace=True)\n",
    "    df = df.filter(regex='_3UTR')\n",
    "    \n",
    "    # drop the _3UTR_log10 suffix from the column names\n",
    "    df.columns = df.columns.str.replace('_3UTR', '')\n",
    "\n",
    "    single_dfs[key] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the mirna data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get only the high confidence microRNAs in mirbase\n",
    "mirbase = pd.read_csv(\"../microrna_data/mirbase_extended.csv\", index_col=0)\n",
    "mirbase_high_confidence = mirbase[mirbase[\"confidence\"] == \"high\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mirna_input_folder_microarray = \"../microrna_data/11_input/microarray\"\n",
    "mirna_input_folder_sequencing = \"../microrna_data/11_input/sequencing\"\n",
    "    \n",
    "# get the name of all files in the microarray folder\n",
    "microarray_files = os.listdir(mirna_input_folder_microarray)\n",
    "# get the name of all files in the sequencing folder\n",
    "sequencing_files = os.listdir(mirna_input_folder_sequencing)\n",
    "\n",
    "# read them into dictionaries\n",
    "microarray_dict = {}\n",
    "sequencing_dict = {}\n",
    "for microarray_file in microarray_files:\n",
    "    if microarray_file.endswith(\".csv\"):\n",
    "        microarray_dict[microarray_file.split('.')[0]] = pd.read_csv(os.path.join(mirna_input_folder_microarray, microarray_file), index_col=0)\n",
    "for sequencing_file in sequencing_files:\n",
    "    if sequencing_file.endswith(\".csv\"):\n",
    "        sequencing_dict[sequencing_file.split('.')[0]] = pd.read_csv(os.path.join(mirna_input_folder_sequencing, sequencing_file), index_col=0)\n",
    "        \n",
    "# join these dictionaries\n",
    "mirna_dict = {**microarray_dict, **sequencing_dict}       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_metadata = pd.read_excel(\"../microrna_data/11_input/dataset_metadata.xlsx\")\n",
    "\n",
    "# reorganize the order in mirna dict to match the order in dataset_metadata[\"Name\"]\n",
    "mirna_dict = {key: mirna_dict[key] for key in dataset_metadata[\"Name\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over the rest of the DataFrames and update the set to keep only common indices\n",
    "for key in mirna_dict:\n",
    "    print(f\"Length of {key}:\", len(mirna_dict[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter them to common mirnas\n",
    "initial_key = next(iter(mirna_dict))  # Get the first key from the dictionary\n",
    "common_indices = set(mirna_dict[initial_key].index)\n",
    "\n",
    "# iterate over the rest of the DataFrames and update the set to keep only common indices\n",
    "for key in mirna_dict:\n",
    "    if key != initial_key:\n",
    "        current_indices = set(mirna_dict[key].index)\n",
    "        common_indices.intersection_update(current_indices)\n",
    "\n",
    "# common_indices contains the indices present in all datasets\n",
    "common_mirnas = list(common_indices)\n",
    "\n",
    "# filter them to high confidence data in mirbase, then normalize and make them log10\n",
    "for key in mirna_dict.keys():\n",
    "    df = mirna_dict[key].loc[common_mirnas, :]\n",
    "    \n",
    "    # filter to high confidence\n",
    "    df = df[df.index.isin(mirbase_high_confidence.index)]\n",
    "    \n",
    "    # normalize to a sum of 10E6\n",
    "    df = normalize_expr_df_to_rpm(df)\n",
    "    \n",
    "    # set all values smaller than 100 to 100\n",
    "    df[df < 100] = 100\n",
    "    \n",
    "    mirna_dict[key] = np.log10(df)\n",
    "    print(key, len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "current_plot_folder = f\"{plot_folder}/mirna_dataset_correlations\"\n",
    "if not os.path.exists(current_plot_folder):\n",
    "    os.makedirs(current_plot_folder)\n",
    "\n",
    "cell_lines = cell_lines_measured\n",
    "keys = list(mirna_dict.keys())\n",
    "no_datasets = len(keys)\n",
    "\n",
    "dataset_correlations = {cell_line: pd.DataFrame(columns=keys, index=keys) for cell_line in cell_lines}\n",
    "for cell_line in cell_lines:\n",
    "    # Determine the number of valid plots for this cell line\n",
    "    valid_keys = [key for key in keys if cell_line in mirna_dict[key]]\n",
    "    no_datasets = len(valid_keys)\n",
    "\n",
    "    fig, axes = plt.subplots(no_datasets, no_datasets, figsize=(no_datasets*0.6, no_datasets*0.6))\n",
    "    plt.subplots_adjust(hspace=0.1, wspace=0.1)\n",
    "\n",
    "    print(cell_line, no_datasets)\n",
    "    \n",
    "    if no_datasets == 1:\n",
    "        continue\n",
    "    plot_count = 0\n",
    "    for i in range(no_datasets):\n",
    "        for j in range(no_datasets):\n",
    "            row = i\n",
    "            col = j\n",
    "            ax = axes[col, row]\n",
    "            \n",
    "            # Get the data for each key\n",
    "            mirna_x = mirna_dict[valid_keys[row]][cell_line]\n",
    "            mirna_y = mirna_dict[valid_keys[col]][cell_line]\n",
    "\n",
    "            # Plot data\n",
    "            ax.scatter(mirna_x, mirna_y, color=\"tab:blue\", s=1.5, edgecolor=\"none\", rasterized=True)\n",
    "            r2 = stats.pearsonr(mirna_x, mirna_y)[0] ** 2\n",
    "            \n",
    "            # save the correlation\n",
    "            dataset_correlations[cell_line].loc[valid_keys[row], valid_keys[col]] = r2\n",
    "            \n",
    "            title_set1 = dataset_metadata[dataset_metadata[\"Name\"] == valid_keys[row]][\"Abbrev_name\"].values[0]\n",
    "            title_set2 = dataset_metadata[dataset_metadata[\"Name\"] == valid_keys[col]][\"Abbrev_name\"].values[0]\n",
    "            #ax.set_title(f\"{title_set1} vs {title_set2}\", fontsize=7)\n",
    "            \n",
    "            if j == no_datasets - 1:\n",
    "                ax.set_xlabel(title_set1, fontsize=6.5)\n",
    "\n",
    "            if i == 0:\n",
    "                ax.set_ylabel(title_set2, fontsize=6.5)\n",
    "                \n",
    "            ax.set_xlim(1.5, 6)\n",
    "            ax.set_ylim(1.5, 6)\n",
    "            \n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            ax.set_xticklabels([])\n",
    "            ax.set_yticklabels([])\n",
    "            ax.text(1.7, 5, f\"{r2:.2f}\".lstrip('0'), fontsize=6, bbox=dict(facecolor='white', alpha=1, edgecolor='none', boxstyle='round,pad=0.1'))\n",
    "            \n",
    "            if i==0 and j==2:\n",
    "                ax.text(0.5, 1.1, \"Aff.: Affymetrix microarray\\nAgi.: Agilent microarray\\nSt. Seq: Standard Sequencing\\nIm. Seq: Improved Sequencing\", fontsize=7)\n",
    "            \n",
    "            plot_count += 1\n",
    "\n",
    "    # Hide unused axes in the upper right triangle\n",
    "    for x in range(no_datasets):\n",
    "        for y in range(no_datasets):\n",
    "            if x - 1 < y:\n",
    "                axes[x, y].set_visible(False)\n",
    "    \n",
    "    \n",
    "    for format in [\"png\", \"svg\"]:\n",
    "        plt.savefig(f\"{current_plot_folder}/{cell_line}_mirna_correlations.{format}\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_correlations_average = pd.DataFrame(columns=keys, index=keys)\n",
    "dataset_correlations_average = dataset_correlations_average.fillna(0)\n",
    "dataset_correlations_count = pd.DataFrame(columns=keys, index=keys)\n",
    "dataset_correlations_count = dataset_correlations_count.fillna(0)\n",
    "\n",
    "for cell_line in cell_lines:\n",
    "    # add the count to non-NaN values\n",
    "    mask = dataset_correlations[cell_line].notnull()\n",
    "    dataset_correlations_count[mask] += 1\n",
    "\n",
    "    dataset_correlations_average += dataset_correlations[cell_line].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_correlations_average[dataset_correlations_average == 0] = np.nan\n",
    "dataset_correlations_average = dataset_correlations_average / dataset_correlations_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder the average based on the dataset_metadata[\"Name\"] column\n",
    "dataset_correlations_average = dataset_correlations_average.reindex(dataset_metadata[\"Name\"], axis=0)\n",
    "# do the same for the columns\n",
    "dataset_correlations_average = dataset_correlations_average.reindex(dataset_metadata[\"Name\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a heatmap\n",
    "current_plot_folder = f\"{plot_folder}/mirna_dataset_correlations\"\n",
    "if not os.path.exists(current_plot_folder):\n",
    "    os.makedirs(current_plot_folder)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3, 2.86))\n",
    "\n",
    "mask = np.triu(np.ones_like(dataset_correlations_average, dtype=bool))\n",
    "\n",
    "sns.heatmap(dataset_correlations_average, mask=mask, cmap=\"viridis\", ax=ax, vmin=0.2, vmax=0.8, cbar_kws={'label': r'$r^2$'}, square=True)\n",
    "# set the xticks to dataset_metadata[\"Abbrev_name\"]\n",
    "plt.xticks(ticks=np.arange(len(dataset_metadata))+0.5, labels=dataset_metadata[\"Abbrev_name\"], rotation=90)\n",
    "# set the yticks to dataset_metadata[\"Abbrev_name\"]\n",
    "plt.yticks(ticks=np.arange(len(dataset_metadata))+0.5, labels=dataset_metadata[\"Abbrev_name\"], rotation=0)\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"\")\n",
    "for format in [\"png\", \"svg\"]:\n",
    "    plt.savefig(f\"{current_plot_folder}/mirna_correlations_heatmap.{format}\", dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine cross dataset correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the Hill function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hill_func_log_scales(x_data, dataset_indices, c1=3, c2=10, *scales):\n",
    "    \"\"\"This is a hill function for a set of microRNA expression values that can be scaled individually.\n",
    "    \n",
    "    The expression is assumed to be normalized to one.\n",
    "    The microRNA data is assumed to be log10.\n",
    "    The return value is also log10.\"\"\"\n",
    "    c1 = 10**c1\n",
    "    c2 = 10**c2\n",
    "    results = []\n",
    "\n",
    "    for i, scale in enumerate(scales):\n",
    "        mask = (dataset_indices == i)\n",
    "        x = x_data[mask] + scale\n",
    "        x = 10**x\n",
    "        result = (1 / (1 + x / c1)) * (1 + x / c2)\n",
    "        results.append( np.log10( result ))\n",
    "    return np.concatenate(results)\n",
    "\n",
    "def hill_func_log_regular(x, c1=3, c2=10):\n",
    "    \"\"\"The expression is assumed to be normalized to one.\n",
    "    The microRNA data is assumed to be log10.\n",
    "    The return value is also log10.\"\"\"\n",
    "    x = 10**x\n",
    "    c1 = 10**c1\n",
    "    c2 = 10**c2\n",
    "    \n",
    "    result = (1 / (1 + x / c1)) * (1 + x / c2)\n",
    "    return np.log10(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "r2_vals = {}\n",
    "rmsd_vals = {}\n",
    "x_range_log = np.arange(0, 5.5, 0.01)\n",
    "for knockdown_key in single_dfs.keys():\n",
    "    r2_vals[knockdown_key] = pd.DataFrame(index=cell_lines_measured, columns=mirna_dict.keys())\n",
    "    rmsd_vals[knockdown_key] = pd.DataFrame(index=cell_lines_measured, columns=mirna_dict.keys())\n",
    "    # create a plot folder for this knockdown_key\n",
    "    current_plot_folder = os.path.join(plot_folder, knockdown_key)\n",
    "    # create it if it doesn't exist\n",
    "    if not os.path.exists(current_plot_folder):\n",
    "        os.makedirs(current_plot_folder)\n",
    "    \n",
    "    for mirna_key in mirna_dict.keys():\n",
    "        df_expression = mirna_dict[mirna_key].copy()\n",
    "        df_knockdown = single_dfs[knockdown_key].copy()\n",
    "        \n",
    "        # get the cell lines as the column intersections\n",
    "        current_cell_lines = list(set(df_expression.columns).intersection(df_knockdown.columns))\n",
    "        \n",
    "        # get the common index as the index intersection\n",
    "        common_mirnas = list(set(df_expression.index).intersection(df_knockdown.index))\n",
    "        \n",
    "        # constrain the dataframes\n",
    "        df_knockdown = df_knockdown.loc[common_mirnas, current_cell_lines]\n",
    "        df_expression = df_expression.loc[common_mirnas, current_cell_lines]\n",
    "        \n",
    "        # -----------------------------------------------------------------\n",
    "        # PREPARE DATA\n",
    "        x_data = []\n",
    "        y_data = []\n",
    "        dataset_indices = []\n",
    "        for i, cell_line in enumerate(current_cell_lines):\n",
    "            ex_df = df_expression[cell_line].values\n",
    "            knock_df = df_knockdown[cell_line].values\n",
    "            x_data.append(ex_df)\n",
    "            y_data.append(knock_df)\n",
    "            dataset_indices.append([i] * len(ex_df))\n",
    "\n",
    "        x_data = np.concatenate(x_data)\n",
    "        y_data = np.concatenate(y_data)\n",
    "        dataset_indices = np.concatenate(dataset_indices)\n",
    "\n",
    "\n",
    "        # -----------------------------------------------------------------\n",
    "        # EXECUTE FIT\n",
    "        # set bounds and initial guesses for non-scale fitting parameters\n",
    "        p0 = [3, 10]\n",
    "        num_params = len(p0)\n",
    "        bounds = ([1, 9.99], [10, 10.01])\n",
    "\n",
    "        # Guess initial scale values for all datasets\n",
    "        scale_guesses = [0 for _ in range(len(current_cell_lines))]\n",
    "        scale_bounds_min = [-2 for _ in range(len(current_cell_lines))]\n",
    "        scale_bounds_max = [2 for _ in range(len(current_cell_lines))]\n",
    "\n",
    "        # set scale for HEK293T to 0\n",
    "        scale_bounds_min[0] = -0.001\n",
    "        scale_bounds_max[0] = 0.001\n",
    "\n",
    "        # set up parameters\n",
    "        p0_scale = p0 + scale_guesses\n",
    "        bounds_scale = (bounds[0]+scale_bounds_min, bounds[1]+scale_bounds_max)\n",
    "\n",
    "        popt_scales, pcov = popt_scales_filter, pcov = opt.curve_fit(\n",
    "            lambda x, *params: hill_func_log_scales(x, dataset_indices, *params),\n",
    "            x_data,\n",
    "            y_data,\n",
    "            p0=p0_scale,\n",
    "            bounds=bounds_scale,\n",
    "            maxfev=5000\n",
    "        )\n",
    "\n",
    "        scales = list(popt_scales[num_params:])\n",
    "        hill_params = popt_scales[:num_params]\n",
    "\n",
    "        # -----------------------------------------------------------------\n",
    "        # PLOT AND SAVE CORRELATION\n",
    "\n",
    "        for i, cell_line in enumerate(current_cell_lines):\n",
    "            current_scale = scales[i]\n",
    "            \n",
    "            plt.figure(figsize=(3,2))\n",
    "            \n",
    "            plt.scatter(df_expression[f\"{cell_line}\"]+current_scale, df_knockdown[f\"{cell_line}\"], s=5, color=\"black\")\n",
    "            plt.plot(x_range_log, hill_func_log_regular(x_range_log,\n",
    "                        *hill_params), color=\"forestgreen\", linewidth=2, label=\"fit\")\n",
    "\n",
    "            # calculate the R2 value\n",
    "            r2 = stats.pearsonr(df_knockdown[f\"{cell_line}\"],\n",
    "                                hill_func_log_regular(df_expression[f\"{cell_line}\"]+current_scale,\n",
    "                                *hill_params))[0]**2\n",
    "            r2_vals[knockdown_key].loc[cell_line, mirna_key] = r2\n",
    "            \n",
    "            # calculate the RMSD value\n",
    "            rmsd = np.sqrt(np.mean((df_knockdown[f\"{cell_line}\"]-\n",
    "                                    hill_func_log_regular(df_expression[f\"{cell_line}\"]+current_scale,\n",
    "                                    *hill_params))**2))\n",
    "            rmsd_vals[knockdown_key].loc[cell_line, mirna_key] = rmsd\n",
    "\n",
    "\n",
    "            plt.xlabel(\"miRNA expression\")\n",
    "            plt.ylabel(r\"log$_{10}$(RNA/DNA)\")\n",
    "            plt.title(f\"{mirna_key},{knockdown_key},{cell_line}\\nr2 = {round(r2, 2)}, rmsd = {round(rmsd, 2)}\", fontsize=7)\n",
    "\n",
    "            plt.xlim(0, 5.5)\n",
    "            plt.ylim(-1.7, 0.25)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            for format in [\"png\", \"svg\"]:\n",
    "                plt.savefig(f\"{current_plot_folder}/{knockdown_key}_{mirna_key}_{cell_line}.{format}\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "r2_vals_copy = r2_vals.copy()\n",
    "for knockdown_key in r2_vals_copy.keys():\n",
    "    curr_r2_vals = r2_vals_copy[knockdown_key].copy().astype(\"float\")\n",
    "    \n",
    "    # filter to datasets that exist in curr_r2_vals AND dataset_metadata\n",
    "    curr_r2_vals = curr_r2_vals.loc[cell_lines_measured, dataset_metadata[\"Name\"]]\n",
    "    \n",
    "    # add the Type of the dataset\n",
    "    curr_r2_vals = curr_r2_vals.T\n",
    "    curr_r2_vals = curr_r2_vals.join(dataset_metadata.set_index(\"Name\")[\"Type\"])\n",
    "    r2_vals_copy[knockdown_key] = curr_r2_vals\n",
    "    \n",
    "    # create a heatmap\n",
    "    plt.figure(figsize=(3,2.7))\n",
    "    sns.heatmap(curr_r2_vals[cell_lines_measured], vmin=0.2, vmax=0.8, cmap=\"viridis\", annot=True, fmt=\".2f\", cbar_kws={'label': r'r$^2$'})\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(ticks=np.arange(0.5, len(dataset_metadata)+0.5, 1), labels=(dataset_metadata[\"Abbrev_name\"]))\n",
    "    \n",
    "    plt.title(f\"{knockdown_key}\")\n",
    "    plt.tight_layout()\n",
    "    for i, entry in enumerate(dataset_metadata[\"Platform\"].values):\n",
    "        plt.text(20, i, entry, ha=\"center\", va=\"center\", fontsize=7)\n",
    "    for format in [\"png\", \"svg\"]:\n",
    "        plt.savefig(os.path.join(plot_folder, f\"{knockdown_key}_R2.{format}\"), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "for knockdown_key in r2_vals_copy.keys():\n",
    "    curr_r2_vals = r2_vals_copy[knockdown_key].copy()\n",
    "    curr_r2_vals[\"Type\"] = curr_r2_vals[\"Type\"].replace({\"Affymetrix microarray\": \"Affymetrix\\nmicroarray\",\n",
    "                                                         \"Agilent microarray\": \"Agilent\",\n",
    "                                                         \"standard NGS\": \"basic\\nNGS\", \n",
    "                                                         \"improved NGS\": \"improved\"})\n",
    "    \n",
    "    # unroll along cell lines (except for the Type column)\n",
    "    # I don't think this is wise - it'll lead to a single dataset dominating the boxplot\n",
    "    # curr_r2_vals = pd.melt(curr_r2_vals, id_vars=\"Type\", var_name=\"Cell line\", value_name=\"R2\")\n",
    "    # average over cell lines\n",
    "    curr_r2_vals[\"mean\"] = curr_r2_vals[cell_lines_measured].mean(axis=1)\n",
    "    print(knockdown_key)\n",
    "    print(curr_r2_vals[\"mean\"].groupby(curr_r2_vals[\"Type\"]).mean())\n",
    "    \n",
    "    # create a boxplot\n",
    "    # plt.figure(figsize=(2,1.6))\n",
    "    plt.figure(figsize=(2,1.3))\n",
    "    sns.boxplot(data=curr_r2_vals, x=\"Type\", y=\"mean\", width=0.6, palette=\"viridis\", showfliers=True, flierprops=dict(marker='o', markersize=2))\n",
    "    \n",
    "    plt.ylabel(r\"r$^2$\")\n",
    "    plt.xticks(fontsize=6.5)\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.tight_layout()\n",
    "    for format in [\"png\", \"svg\"]:\n",
    "        plt.savefig(os.path.join(plot_folder, f\"{knockdown_key}_R2_boxplot.{format}\"), dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
