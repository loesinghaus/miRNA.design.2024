{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import scipy.optimize as opt\n",
    "import pickle\n",
    "import itertools\n",
    "import random\n",
    "import os\n",
    "import ast\n",
    "from library2_utils.color_scheme import cell_line_colors, cell_line_symbols\n",
    "from library2_utils.transfer_functions import transfer_function\n",
    "from library2_utils.mirna_combinations import get_combinations\n",
    "from library2_utils.additive_model import add_mirna_expression\n",
    "from library2_utils.design_utilities import tsi\n",
    "\n",
    "# set the font size\n",
    "plt.rcParams.update({'font.size': 7})\n",
    "# set Helvetica globally\n",
    "plt.rcParams['font.family'] = 'Helvetica'\n",
    "\n",
    "cell_lines_subset = [\"HEK293T\", \"HeLa\", \"SKNSH\", \"MCF7\", \"HUH7\", \"A549\"]\n",
    "cell_lines_rest = [\"HaCaT\", \"JEG3\", \"Tera1\", \"PC3\"]\n",
    "cell_lines_measured = cell_lines_subset + cell_lines_rest\n",
    "\n",
    "cell_lines_measured_UTR = [cell_line + \"_3UTR\" for cell_line in cell_lines_measured]\n",
    "cell_lines_measured_pred = [\"predicted_\" + cell_line for cell_line in cell_lines_measured]\n",
    "cell_lines_all_target = [\"target_\" + cell_line for cell_line in cell_lines_measured]\n",
    "\n",
    "label_rename = {\n",
    "    \"HUH-7\": \"HUH7\",\n",
    "    \"JEG-3\": \"JEG3\",\n",
    "    \"Tera-1\": \"Tera1\",\n",
    "    \"SK-N-SH\": \"SKNSH\",\n",
    "    \"PC-3\": \"PC3\",\n",
    "}\n",
    "\n",
    "# get mirbase\n",
    "mirbase = pd.read_csv(\"../microrna_data/mirbase_extended.csv\", index_col=0)\n",
    "\n",
    "base_plot_folder = \"../plots/16_design_for_tissues\"\n",
    "# create folder if it does not exist\n",
    "if not os.path.exists(base_plot_folder):\n",
    "    os.makedirs(base_plot_folder)\n",
    "output_folder = \"../outputs/16_design_for_tissues\"\n",
    "# create folder if it does not exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "\n",
    "key_shorthand = {\n",
    "    \"24_miRNA_full_subset_quality_AND4\": \"quality_subset_AND4\",\n",
    "    \"25_miRNA_full_subset_quality_AND5\": \"quality_subset_AND5\",\n",
    "    \"26_miRNA_full_subset_quality_AND6\": \"quality_subset_AND6\",\n",
    "    \"27_miRNA_full_quality_AND4\": \"quality_all_AND4\",\n",
    "    \"28_miRNA_full_quality_AND5\": \"quality_all_AND5\",\n",
    "    \"29_miRNA_full_quality_AND6\": \"quality_all_AND6\",\n",
    "    \"30_miRNA_AND4_subset_mse_designs\": \"mse_subset_AND4\",\n",
    "    \"31_miRNA_AND5_subset_mse_designs\": \"mse_subset_AND5\",\n",
    "    \"32_miRNA_AND6_subset_mse_designs\": \"mse_subset_AND6\",\n",
    "    \"33_miRNA_AND4_all_mse_designs\": \"mse_all_AND4\",\n",
    "    \"34_miRNA_AND5_all_mse_designs\": \"mse_all_AND5\",\n",
    "    \"35_miRNA_AND6_all_mse_designs\": \"mse_all_AND6\",\n",
    "    \"subset_quality\": \"subset_quality\",\n",
    "    \"full_quality\": \"full_quality\",\n",
    "    \"subset_mse\": \"subset_mse\",\n",
    "    \"all_mse\": \"all_mse\"\n",
    "}\n",
    "\n",
    "main_colormap = \"rocket\"\n",
    "box_color = \"deepskyblue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_processed_folder = \"../microrna_data/15_human_data_merge/processed\"\n",
    "merged_dataset = pd.read_csv(os.path.join(dataset_processed_folder, \"15.3_merged_tissue_datasets.csv\"), index_col=0)\n",
    "\n",
    "with open(os.path.join(dataset_processed_folder, \"tissue_data_popt.pkl\"), \"rb\") as f:\n",
    "    tissue_popt = pickle.load(f)\n",
    "with open(os.path.join(dataset_processed_folder, \"tissue_data_scales.pkl\"), \"rb\") as f:\n",
    "    tissue_scales = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE TISSUE DESIGNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_mirna_combs(mirna_expr, combs):\n",
    "    \"\"\"Takes a dataframe with microRNA expressions and tuples of combinations.\n",
    "    Returns a dataframe with the added expression of the microRNAs in the constructs.\n",
    "    \n",
    "    mirna_expr: dataframe with microRNA expression (index: microRNA names, columns: cell lines)\n",
    "    construct_df: dataframe with construct information (index: construct names, columns: microRNA names)\"\"\"\n",
    "    # if isinstance(combs[0], tuple):\n",
    "    multiindex = pd.MultiIndex.from_tuples(combs, names=[f'miRNA{i+1}' for i in range(len(combs[0]))])\n",
    "    added_expression = pd.DataFrame(columns=mirna_expr.columns, index=multiindex)\n",
    "    added_expression = added_expression.astype(\"float\")\n",
    "    added_expression = added_expression.sort_index()\n",
    "    \n",
    "    for i, comb in enumerate(combs):\n",
    "        added_expression.loc[comb,:] = mirna_expr.loc[comb,:].sum(axis=0).values\n",
    "\n",
    "    return added_expression\n",
    "\n",
    "def calculate_mse(df, mse_target, loss_emphasis):\n",
    "    \"\"\"This function calculates the mean squared error of a design for a given target stability distribution.\n",
    "    df has expression values for different cell lines in the columns and microRNAs in the rows.\n",
    "    mse_target is a dataframe with the target distribution across cell lines as a single row.\"\"\"\n",
    "        \n",
    "    mse = (df - mse_target)**2\n",
    "    mse = mse.mul(loss_emphasis, axis=1)\n",
    "    mse = mse.mean(axis=1)\n",
    "\n",
    "    return mse\n",
    "\n",
    "def calculate_fitness(pop, expression, loss_emphasis={}, mse_target=[]):\n",
    "    \"\"\"This function calculates the fitness of a population of designs based on the projected stabiltiy and target.\"\"\"\n",
    "    \n",
    "    # Calculate the stability levels for the designs in the population according to the additive model\n",
    "    add_expr = add_mirna_combs(expression, pop).apply(lambda x: transfer_function(x, *tissue_popt))\n",
    "\n",
    "    # if loss emphasis is empty, generate it\n",
    "    if len(loss_emphasis) == 0:\n",
    "        loss_emphasis = {cell_line: 1 for cell_line in add_expr.columns}\n",
    "\n",
    "    mse = calculate_mse(add_expr, mse_target, loss_emphasis)\n",
    "    fitness = 1/mse\n",
    "\n",
    "    return fitness\n",
    "\n",
    "def evaluate_fitness(pop, expression, loss_emphasis={}, mse_target=[]):\n",
    "    add_expr = add_mirna_combs(expression, pop).apply(lambda x: transfer_function(x, *tissue_popt))\n",
    "    add_expr[\"quality\"] = calculate_fitness(pop, expression, loss_emphasis, mse_target)\n",
    "\n",
    "    return add_expr\n",
    "\n",
    "def drop_duplicates(df):\n",
    "    \"\"\" Drop all duplicate designs. Assumes that the indices are tuples of microRNAs. \"\"\"\n",
    "    sorted_idx = df.index.map(sorted)\n",
    "    df['sorted_index'] = [tuple(i) for i in sorted_idx]\n",
    "    duplicates = df.duplicated(subset='sorted_index', keep=False)\n",
    "    df = df.drop_duplicates(subset='sorted_index', keep='first').drop(columns='sorted_index')\n",
    "    return df, duplicates \n",
    "\n",
    "def select_parents(fitnesses):\n",
    "    \"\"\"Selects two parents from the population using tournament selection.\"\"\"\n",
    "    # Tournament selection\n",
    "    tournament_size = 3\n",
    "    parents = []\n",
    "\n",
    "    for _ in range(2):  # Select two parents\n",
    "        tournament = fitnesses.sample(tournament_size)\n",
    "        # select the best individual\n",
    "        winner = tournament.sort_values(ascending=False).index[0]\n",
    "        parents.append(winner)\n",
    "\n",
    "    return tuple(parents)\n",
    "\n",
    "def crossover(parent1, parent2, n):\n",
    "    # Single point crossover\n",
    "    idx = random.randint(0, n-1)\n",
    "    child = parent1[:idx] + parent2[idx:]\n",
    "    return child\n",
    "\n",
    "def mutate(child, miRNAs, n):\n",
    "    # Randomly replace one microRNA with another\n",
    "    if random.random() < 0.2:  # 20% mutation rate\n",
    "        idx = random.randint(0, n-1)\n",
    "        new_mirna = random.choice(miRNAs)\n",
    "        child = list(child)\n",
    "        child[idx] = new_mirna\n",
    "    return tuple(child)\n",
    "\n",
    "# -----------------------------------------------------------------------\n",
    "\n",
    "def determine_mirna_usage(df):\n",
    "    usage_dict = {}\n",
    "    used_mirnas = df.index.tolist()\n",
    "    for design in used_mirnas:\n",
    "        for mirna in design:\n",
    "            if mirna in usage_dict:\n",
    "                usage_dict[mirna] += 1\n",
    "            else:\n",
    "                usage_dict[mirna] = 1\n",
    "    \n",
    "    # sort dict by value\n",
    "    usage_dict = {k: v for k, v in sorted(usage_dict.items(), key=lambda item: item[1], reverse=True)}\n",
    "    return usage_dict\n",
    "\n",
    "def count_mirnas_per_design(df):\n",
    "    \"\"\"Combinations is a list of dataframe of designs.\n",
    "    Returns a dictionary with the number of times each miRNA is used across the designs.\n",
    "    If a single miRNA is used multiple times in a single design, it is counted only once.\"\"\"\n",
    "    combinations = df.index.tolist()\n",
    "\n",
    "    mirna_count = {}\n",
    "    for design in combinations:\n",
    "        design_count = {}\n",
    "        for mirna in design:\n",
    "            if mirna in design_count:\n",
    "                continue\n",
    "            else:\n",
    "                design_count[mirna] = 1\n",
    "            if mirna in mirna_count:\n",
    "                mirna_count[mirna] += 1\n",
    "            else:\n",
    "                mirna_count[mirna] = 1\n",
    "\n",
    "    mirna_count_df = pd.DataFrame.from_dict(mirna_count, orient='index', columns=['count'])\n",
    "    mirna_count_df = mirna_count_df.sort_values(by=['count'], ascending=False)            \n",
    "    return mirna_count_df\n",
    "\n",
    "# -----------------------------------------------------------------------\n",
    "\n",
    "def generate_genetic_design(target, n_mirnas, mirnas, mirna_expression, loss_emphasis={},\n",
    "                            no_designs=10, generations=30, population_size=500):\n",
    "    \n",
    "    # Initial population\n",
    "    population = [tuple(random.choice(mirnas) for _ in range(n_mirnas)) for _ in range(population_size)]\n",
    "\n",
    "    # Run the GA for a set number of generations\n",
    "    for generation in range(generations):\n",
    "        fitnesses = calculate_fitness(pop=population,\n",
    "                                      expression=mirna_expression,\n",
    "                                      loss_emphasis=loss_emphasis,\n",
    "                                      mse_target=target)\n",
    "        new_population = []\n",
    "        for _ in range(population_size):\n",
    "            parent1, parent2 = select_parents(fitnesses)\n",
    "            child = crossover(parent1, parent2, n_mirnas)\n",
    "            child = mutate(child, mirnas, n_mirnas)\n",
    "            new_population.append(child)\n",
    "        population = new_population\n",
    "\n",
    "    # Get the best designs\n",
    "    designs = evaluate_fitness(population, mirna_expression, loss_emphasis=loss_emphasis, mse_target=target)\n",
    "    designs, _ = drop_duplicates(designs)\n",
    "    designs.sort_values(by=['quality'], ascending=False, inplace=True)\n",
    "    designs = designs.head(no_designs)\n",
    "\n",
    "    return designs\n",
    "\n",
    "def add_numbered_index(df, base_name):\n",
    "    \"\"\"Df is assumed to have a multiindex of microRNAs. First, convert the multi-index to columns.\"\"\"\n",
    "    df = df.reset_index()\n",
    "    \"\"\"Then, add a column with the design number.\"\"\"\n",
    "    df.index = [f\"{base_name}_{i+1}\" for i in range(len(df))]\n",
    "    return df\n",
    "\n",
    "def generate_mse_designs(mse_targets, designs_per_target, base_name, mirna_data,\n",
    "                         loss=\"mse\", n_mirnas=4, loss_emphases={}, increase_diversity=1):\n",
    "    # List of microRNAs and their impacts\n",
    "    miRNAs = list(mirna_data.index)\n",
    "\n",
    "    all_designs = []\n",
    "\n",
    "    if len(loss_emphases) == 0:\n",
    "        loss_emphases = [{} for i in range(len(mse_targets))]\n",
    "        \n",
    "    for i, mse_target in enumerate(mse_targets):\n",
    "        print(f\"Processing {base_name} {i+1}/{len(mse_targets)}\")\n",
    "        miRNAs_filter = miRNAs.copy()\n",
    "        target_designs = []\n",
    "        \n",
    "        for _ in range(increase_diversity):\n",
    "            designs = generate_genetic_design(\n",
    "                target=mse_target,\n",
    "                loss_emphasis=loss_emphases[i],\n",
    "                n_mirnas=n_mirnas,\n",
    "                mirnas=miRNAs_filter,\n",
    "                mirna_expression=mirna_data,\n",
    "                no_designs=int(designs_per_target/increase_diversity),\n",
    "            )\n",
    "\n",
    "            designs[\"target\"] = str(mse_target)\n",
    "            designs[\"emphasis\"] = str(loss_emphases[i])\n",
    "            designs[\"type\"] = base_name\n",
    "\n",
    "            used_mirnas = count_mirnas_per_design(designs)\n",
    "            top_mirnas = used_mirnas.head(5).index.to_list()\n",
    "            # print(cell_line, \" \", top_mirnas)\n",
    "            miRNAs_filter = [mirna for mirna in miRNAs_filter if mirna not in top_mirnas]\n",
    "            target_designs.append(designs.head(int(designs_per_target/increase_diversity)))\n",
    "\n",
    "        target_designs = pd.concat(target_designs)\n",
    "        all_designs.append(target_designs)\n",
    "        \n",
    "    all_designs_df = pd.concat(all_designs)\n",
    "\n",
    "    return all_designs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_multiple_mse_designs(base_name, mirna_dataset, targets, emphases, cell_lines_used,\n",
    "                              loss, sublabel, designs_per_cell_line, n):\n",
    "    \n",
    "    \"\"\"This function generates designs for multiple targets and loss emphases.\"\"\"\n",
    "    \n",
    "    diversity = 1\n",
    "    designs = generate_mse_designs(mse_targets=targets,\n",
    "                            designs_per_target=designs_per_cell_line, \n",
    "                            mirna_data=mirna_dataset,\n",
    "                            base_name=base_name,\n",
    "                            loss_emphases=emphases,\n",
    "                            n_mirnas=n,\n",
    "                            increase_diversity=diversity)\n",
    "    \n",
    "    designs[cell_lines_used] = designs[cell_lines_used].astype(\"float\")\n",
    "    designs[\"sublabel\"] = str(sublabel)\n",
    "    base_number = 1\n",
    "        \n",
    "    designs = add_numbered_index(designs, base_name=f\"{base_number}_miRNA_full_{base_name}_AND{n}\")\n",
    "    return designs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataset_tissues = merged_dataset.drop(columns=cell_lines_measured)\n",
    "merged_dataset_tissues = 10**merged_dataset_tissues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataset_tissues_log10 = np.log10(merged_dataset_tissues)\n",
    "plt.figure(figsize=(5.5, 5.5))\n",
    "sns.heatmap(merged_dataset_tissues_log10.corr()**2, cmap=\"viridis\", square=True,\n",
    "            cbar_kws={'label': r'$r^2$', 'shrink': 0.8})\n",
    "plt.savefig(os.path.join(base_plot_folder, \"tissue_correlation_heatmap.png\"), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "df_t = merged_dataset_tissues_log10.transpose()\n",
    "\n",
    "# Perform hierarchical clustering\n",
    "linked = linkage(df_t, method='ward')\n",
    "\n",
    "# Plot the dendrogram\n",
    "plt.figure(figsize=(4, 3))\n",
    "dendrogram(linked, labels=df_t.index, leaf_rotation=90)\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('Tissues')\n",
    "plt.ylabel('Distance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# broad organs\n",
    "broad_organs = ['brain', 'bone', 'muscle', 'stomach', 'liver', 'lung', 'thyroid', 'lymph_node', 'spleen', 'kidney', 'testis', 'skin', 'adipocyte']\n",
    "# brain regions\n",
    "brain_regions = ['thalamus', 'white_matter', 'grey_matter', 'nucleus_caudatus', 'cerebellum', 'spinal_cord', 'dura_mater']\n",
    "# target numbers\n",
    "target_numbers = [1, 2, 3, 4, 5, 6, 7, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "designs_per_cell_line = 1\n",
    "base_name=\"single_target_broad_organs\"\n",
    "cell_lines_used = broad_organs\n",
    "\n",
    "single_targets = []\n",
    "for i in range(len(cell_lines_used)):\n",
    "    single_target = {cell_line: 1 for cell_line in cell_lines_used}\n",
    "    single_target[cell_lines_used[i]] = 0\n",
    "    single_targets.append(single_target)\n",
    "\n",
    "single_emphases = []\n",
    "for i in range(len(single_targets)):\n",
    "    single_emphasis = {cell_line: 1 for cell_line in cell_lines_used}\n",
    "    single_emphasis[cell_lines_used[i]] = len(cell_lines_used)/2.0\n",
    "    single_emphases.append(single_emphasis)\n",
    "\n",
    "# get the subset of mirna data that is relevant\n",
    "mirna_dataset = merged_dataset_tissues[cell_lines_used]\n",
    "# constrain to miRNAs that are expressed in at least one tissue\n",
    "mirna_dataset = mirna_dataset[mirna_dataset.max(axis=1) > 3000]\n",
    "# create the possibility of leaving out miRNA sites altogether\n",
    "mirna_dataset.loc[\"empty\"] = 0\n",
    "\n",
    "# create an output folder\n",
    "output_folder_curr = os.path.join(output_folder, base_name)\n",
    "os.makedirs(output_folder_curr, exist_ok=True)\n",
    "\n",
    "for target_number in target_numbers:\n",
    "    designs = make_multiple_mse_designs(base_name=base_name,\n",
    "                        targets=single_targets,\n",
    "                        mirna_dataset=mirna_dataset,\n",
    "                        emphases=single_emphases,\n",
    "                        cell_lines_used=cell_lines_used,\n",
    "                        loss=\"mse\",\n",
    "                        sublabel=cell_lines_used,\n",
    "                        n=target_number,\n",
    "                        designs_per_cell_line=designs_per_cell_line)\n",
    "\n",
    "    designs.to_csv(os.path.join(output_folder_curr, f\"designs_{base_name}_{target_number}.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "designs_per_cell_line = 1\n",
    "base_name=\"single_active_broad_organs\"\n",
    "\n",
    "cell_lines_used = broad_organs\n",
    "\n",
    "single_actives = []\n",
    "for i in range(len(cell_lines_used)):\n",
    "    single_active = {cell_line: 0 for cell_line in cell_lines_used}\n",
    "    single_active[cell_lines_used[i]] = 1\n",
    "    single_actives.append(single_active)\n",
    "\n",
    "single_emphases = []\n",
    "for i in range(len(single_actives)):\n",
    "    single_emphasis = {cell_line: 1 for cell_line in cell_lines_used}\n",
    "    single_emphasis[cell_lines_used[i]] = len(cell_lines_used)\n",
    "    single_emphases.append(single_emphasis)\n",
    "    \n",
    "mirna_dataset = merged_dataset_tissues[cell_lines_used]\n",
    "# constrain to miRNAs that are expressed in at least one tissue\n",
    "mirna_dataset = mirna_dataset[mirna_dataset.max(axis=1) > 3000]\n",
    "mirna_dataset.loc[\"empty\"] = 0\n",
    "\n",
    "# create an output folder\n",
    "output_folder_curr = os.path.join(output_folder, base_name)\n",
    "os.makedirs(output_folder_curr, exist_ok=True)\n",
    "\n",
    "for target_number in target_numbers:\n",
    "    designs = make_multiple_mse_designs(base_name=base_name,\n",
    "                        targets=single_actives,\n",
    "                        mirna_dataset=mirna_dataset,\n",
    "                        emphases=single_emphases,\n",
    "                        cell_lines_used=cell_lines_used,\n",
    "                        loss=\"mse\",\n",
    "                        sublabel=cell_lines_used,\n",
    "                        n=target_number,\n",
    "                        designs_per_cell_line=designs_per_cell_line)\n",
    "\n",
    "    designs.to_csv(os.path.join(output_folder_curr, f\"designs_{base_name}_{target_number}.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "designs_per_cell_line = 1\n",
    "base_name=\"single_target_brain_regions\"\n",
    "\n",
    "cell_lines_used = brain_regions\n",
    "\n",
    "single_targets = []\n",
    "for i in range(len(cell_lines_used)):\n",
    "    single_target = {cell_line: 1 for cell_line in cell_lines_used}\n",
    "    single_target[cell_lines_used[i]] = 0\n",
    "    single_targets.append(single_target)\n",
    "\n",
    "single_emphases = []\n",
    "for i in range(len(single_targets)):\n",
    "    single_emphasis = {cell_line: 1 for cell_line in cell_lines_used}\n",
    "    single_emphasis[cell_lines_used[i]] = len(cell_lines_used)/2.0\n",
    "    single_emphases.append(single_emphasis)\n",
    "    \n",
    "mirna_dataset = merged_dataset_tissues[cell_lines_used]\n",
    "# constrain to miRNAs that are expressed in at least one tissue\n",
    "mirna_dataset = mirna_dataset[mirna_dataset.max(axis=1) > 3000]\n",
    "mirna_dataset.loc[\"empty\"] = 0\n",
    "\n",
    "# create an output folder\n",
    "output_folder_curr = os.path.join(output_folder, base_name)\n",
    "os.makedirs(output_folder_curr, exist_ok=True)\n",
    "\n",
    "designs = make_multiple_mse_designs(base_name=base_name,\n",
    "                    targets=single_targets,\n",
    "                    mirna_dataset=mirna_dataset,\n",
    "                    emphases=single_emphases,\n",
    "                    cell_lines_used=cell_lines_used,\n",
    "                    loss=\"mse\",\n",
    "                    sublabel=cell_lines_used,\n",
    "                    n=6,\n",
    "                    designs_per_cell_line=designs_per_cell_line)\n",
    "\n",
    "designs.to_csv(os.path.join(output_folder_curr, f\"designs_{base_name}_6.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "designs_per_cell_line = 1\n",
    "base_name=\"single_active_brain_regions\"\n",
    "\n",
    "cell_lines_used = brain_regions\n",
    "\n",
    "single_actives = []\n",
    "for i in range(len(cell_lines_used)):\n",
    "    single_active = {cell_line: 0 for cell_line in cell_lines_used}\n",
    "    single_active[cell_lines_used[i]] = 1\n",
    "    single_actives.append(single_active)\n",
    "\n",
    "single_emphases = []\n",
    "for i in range(len(single_actives)):\n",
    "    single_emphasis = {cell_line: 1 for cell_line in cell_lines_used}\n",
    "    single_emphasis[cell_lines_used[i]] = len(cell_lines_used)\n",
    "    single_emphases.append(single_emphasis)\n",
    "    \n",
    "mirna_dataset = merged_dataset_tissues[cell_lines_used]\n",
    "# constrain to miRNAs that are expressed in at least one tissue\n",
    "mirna_dataset = mirna_dataset[mirna_dataset.max(axis=1) > 3000]\n",
    "mirna_dataset.loc[\"empty\"] = 0\n",
    "\n",
    "# create an output folder\n",
    "output_folder_curr = os.path.join(output_folder, base_name)\n",
    "os.makedirs(output_folder_curr, exist_ok=True)\n",
    "\n",
    "designs = make_multiple_mse_designs(base_name=base_name,\n",
    "                    targets=single_actives,\n",
    "                    mirna_dataset=mirna_dataset,\n",
    "                    emphases=single_emphases,\n",
    "                    cell_lines_used=cell_lines_used,\n",
    "                    loss=\"mse\",\n",
    "                    sublabel=cell_lines_used,\n",
    "                    n=6,\n",
    "                    designs_per_cell_line=designs_per_cell_line)\n",
    "\n",
    "designs.to_csv(os.path.join(output_folder_curr, f\"designs_{base_name}_6.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the designs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_target_cell_lines(cell_line_dict, target_value=0):\n",
    "    if type(cell_line_dict) == str:\n",
    "        cell_line_dict = ast.literal_eval(cell_line_dict)\n",
    "    result = [cell_line for cell_line, value in cell_line_dict.items() if value == target_value]\n",
    "    # apply rename dictionary\n",
    "    result = [label_rename[cell_line] if cell_line in label_rename else cell_line for cell_line in result]\n",
    "    # make result a tuple\n",
    "    # result = tuple(result)\n",
    "    # make it a clean string\n",
    "    result = \", \".join(result)\n",
    "    return result\n",
    "\n",
    "def get_cell_line_to_row_mapping(df):\n",
    "    \"\"\"The input should be a df that only contains the cell_lines or a list.\"\"\"\n",
    "    cell_line_to_row = {}\n",
    "    i = 0\n",
    "    if type(df) == list:\n",
    "        for cell_line in df:\n",
    "            cell_line_to_row[cell_line] = i\n",
    "            i += 1\n",
    "        return cell_line_to_row\n",
    "    elif type(df) == pd.DataFrame:\n",
    "        for cell_line in df.columns:\n",
    "            cell_line_to_row[cell_line] = i\n",
    "            i += 1\n",
    "    return cell_line_to_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_folder = os.path.join(base_plot_folder, \"tissue_designs\")\n",
    "# create folder if it does not exist\n",
    "if not os.path.exists(plot_folder):\n",
    "    os.makedirs(plot_folder)\n",
    "\n",
    "# broad organs\n",
    "broad_organs = ['brain', 'bone', 'muscle', 'stomach', 'liver', 'lung', 'thyroid', 'lymph_node', 'spleen', 'kidney', 'testis', 'skin', 'adipocyte']\n",
    "# brain regions\n",
    "brain_regions = ['thalamus', 'white_matter', 'grey_matter', 'nucleus_caudatus', 'cerebellum', 'spinal_cord', 'dura_mater']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_design_heatmap(df, filename, organ_dict_or_list, design_type, plot_folder, title=None):\n",
    "    if \"active\" in design_type:\n",
    "        df[\"target_cell_lines\"] = df[\"target\"].apply(lambda x: extract_target_cell_lines(x, 1))\n",
    "    if \"target\" in design_type:\n",
    "        df[\"target_cell_lines\"] = df[\"target\"].apply(lambda x: extract_target_cell_lines(x, 0))\n",
    "    \n",
    "    if type(organ_dict_or_list) == list:\n",
    "        curr_cell_set = [column for column in df.columns if column in organ_dict_or_list]\n",
    "    else:\n",
    "        curr_cell_set = [column for column in df.columns if column in organ_dict_or_list.values()]\n",
    "    \n",
    "    # get a mapping to rows\n",
    "    cell_line_to_row_map = get_cell_line_to_row_mapping(curr_cell_set)\n",
    "\n",
    "    # -----------------------------------------------------------------------\n",
    "    plt.clf()\n",
    "    if \"broad_organs\" in filename:\n",
    "        figsize=(3, 1.8)\n",
    "    if \"brain_regions\" in filename:\n",
    "        figsize=(2, 1.2)\n",
    "    fig, ax = plt.subplots(figsize=figsize) \n",
    "    \n",
    "    # Create the heatmap subplot\n",
    "    sns.heatmap(df[curr_cell_set].T, cmap=main_colormap, vmin=0, vmax=1, fmt=\".2f\", square=True, annot=False,\n",
    "                        cbar=True, cbar_kws={'label': 'stability'}, ax=ax)\n",
    "\n",
    "    x_pos = 0\n",
    "    for index, row in df.iterrows():\n",
    "        target_cell_lines = row[\"target_cell_lines\"]\n",
    "        if \", \" in target_cell_lines:\n",
    "            target_cell_lines = target_cell_lines.split(\", \")\n",
    "            target_rows = [cell_line_to_row_map[cell_line] for cell_line in target_cell_lines]\n",
    "        else:\n",
    "            target_rows = [cell_line_to_row_map[target_cell_lines]]\n",
    "\n",
    "        for target_row in target_rows:\n",
    "            rect = patches.Rectangle((x_pos, target_row), 1, 1, linewidth=1.5, edgecolor=box_color, facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "\n",
    "        x_pos += 1\n",
    "\n",
    "    plt.xlim([-0.1, df[curr_cell_set].shape[0] + 0.1])\n",
    "    plt.ylim([len(df[curr_cell_set].columns) + 0.1, -0.1])\n",
    "    plt.yticks(ticks=np.arange(0.5, len(curr_cell_set)+0.5), labels=[cell.replace(\"predicted_\", \"\").replace(\"_\", \" \") for cell in curr_cell_set], rotation=0)\n",
    "    plt.xticks([])\n",
    "    plt.xlabel(\"Designs\")\n",
    "    \n",
    "    if title:\n",
    "        plt.title(title, fontsize=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    for format in [\"png\", \"svg\"]:\n",
    "        plt.savefig(os.path.join(plot_folder, f\"{filename}.{format}\"), dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_folders = {\n",
    "    \"broad_organs_single_target\": os.path.join(output_folder, \"single_target_broad_organs\"),\n",
    "    \"broad_organs_single_active\": os.path.join(output_folder, \"single_active_broad_organs\"),\n",
    "    \"brain_regions_single_target\": os.path.join(output_folder, \"single_target_brain_regions\"),\n",
    "    \"brain_regions_single_active\": os.path.join(output_folder, \"single_active_brain_regions\"),\n",
    "}\n",
    "plot_folders = {\n",
    "    \"broad_organs_single_target\": os.path.join(plot_folder, \"broad_organs_single_target\"),\n",
    "    \"broad_organs_single_active\": os.path.join(plot_folder, \"broad_organs_single_active\"),\n",
    "    \"brain_regions_single_target\": os.path.join(plot_folder, \"brain_regions_single_target\"),\n",
    "    \"brain_regions_single_active\": os.path.join(plot_folder, \"brain_regions_single_active\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "organs = {\n",
    "    \"broad_organs_single_target\": broad_organs,\n",
    "    \"broad_organs_single_active\": broad_organs,\n",
    "    \"brain_regions_single_target\": brain_regions,\n",
    "    \"brain_regions_single_active\": brain_regions,\n",
    "}\n",
    "\n",
    "current = \"broad_organs_single_target\"\n",
    "for current in list(organs.keys())[:2]:\n",
    "    design_folder = design_folders[current]\n",
    "    # list all files in the folder\n",
    "    design_files = os.listdir(design_folder)\n",
    "    plot_folder_curr = plot_folders[current]\n",
    "    os.makedirs(plot_folder_curr, exist_ok=True)\n",
    "\n",
    "    # iterate over the files\n",
    "    dfs = []\n",
    "    qualities = []\n",
    "    for design_file in design_files:\n",
    "        if design_file.endswith(\".csv\"):\n",
    "            df = pd.read_csv(os.path.join(design_folder, design_file), index_col=0)\n",
    "            dfs.append(df)\n",
    "            plot_design_heatmap(df, design_file.split(\".\")[0], organs[current],\n",
    "                                design_file.split(\".\")[0], plot_folder_curr)\n",
    "                                #title=design_file.split(\".\")[0].split(\"_\")[-1]+\" targets maximum\")\n",
    "            \n",
    "    all_dfs = pd.concat(dfs)\n",
    "    all_dfs[\"target_number\"] = all_dfs.index.str.split(\"_\").str[-2].str[-1]\n",
    "    mirna_columns = [column for column in all_dfs if \"miRNA\" in column]\n",
    "\n",
    "    # replace \"empty\" by nan\n",
    "    all_dfs = all_dfs.replace(\"empty\", np.nan)\n",
    "\n",
    "    # find out how many miRNAs are being used at all\n",
    "    all_dfs[\"targets_used\"] = all_dfs[mirna_columns].count(axis=1)\n",
    "\n",
    "    # find out how many unique miRNAs are being used\n",
    "    all_dfs[\"unique_mirnas\"] = all_dfs[mirna_columns].nunique(axis=1)\n",
    "\n",
    "    # get the maximum quality for each target\n",
    "    all_dfs[\"quality_max\"] = all_dfs.groupby(\"target_cell_lines\")[\"quality\"].transform(\"max\")\n",
    "\n",
    "    # calculate relative qualities\n",
    "    all_dfs[\"quality_relative\"] = 100 * all_dfs[\"quality\"] / all_dfs[\"quality_max\"]\n",
    "    \n",
    "    if \"active\" in current:\n",
    "        all_dfs_active = all_dfs.copy()\n",
    "    if \"target\" in current:\n",
    "        all_dfs_target = all_dfs.copy()\n",
    "    target_numbers = all_dfs[\"target_number\"].unique()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a plot of the mean targets used and unique miRNAs used\n",
    "plt.clf()\n",
    "fig, ax = plt.subplots(figsize=(2, 1.6))\n",
    "mean_by_target = all_dfs_target.groupby(\"target_number\")[\"targets_used\"].mean()\n",
    "std_by_target = all_dfs_target.groupby(\"target_number\")[\"targets_used\"].std()\n",
    "plt.errorbar(x=target_numbers, y=mean_by_target, yerr=std_by_target, label=\"single inactive\",\n",
    "                fmt=\"o-\", color=\"tab:red\", capsize=3, markersize=5)\n",
    "mean_by_target = all_dfs_active.groupby(\"target_number\")[\"targets_used\"].mean()\n",
    "std_by_target = all_dfs_active.groupby(\"target_number\")[\"targets_used\"].std()\n",
    "plt.errorbar(x=target_numbers, y=mean_by_target, yerr=std_by_target, label=\"single active\",\n",
    "                fmt=\"o-\", color=\"tab:blue\", capsize=3, markersize=5)\n",
    "plt.xlabel(\"Maximum allowed number of targets\")\n",
    "plt.ylabel(\"Targets used in designs\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.yticks(np.arange(1, 9, 1))\n",
    "plt.ylim([0.5, 8.5])\n",
    "plt.tight_layout()\n",
    "for format in [\"png\", \"svg\"]:\n",
    "    plt.savefig(os.path.join(plot_folder, f\"mean_targets_used.{format}\"), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 1.8))\n",
    "sns.swarmplot(x='target_number', y='targets_used', data=all_dfs_active, color='tab:red', size=3, alpha=1, label=\"single active\")\n",
    "sns.swarmplot(x='target_number', y='targets_used', data=all_dfs_target, color='tab:blue', size=3, alpha=1, label=\"single inactive\")\n",
    "\n",
    "# Set labels\n",
    "plt.xlabel(\"Maximum allowed number of targets\")\n",
    "plt.ylabel(\"Targets used in design\")\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a plot of the mean targets used and unique miRNAs used\n",
    "plt.clf()\n",
    "fig, ax = plt.subplots(figsize=(2, 1.6))\n",
    "sns.stripplot(x='target_number', y='quality_relative', data=all_dfs_active, alpha=0.6, color='tab:blue', size=3)\n",
    "sns.stripplot(x='target_number', y='quality_relative', data=all_dfs_target, alpha=0.6, color='tab:red', size=3)\n",
    "\n",
    "# Add custom legend\n",
    "ax.scatter([], [], c='tab:red', alpha=0.6, s=9, label=\"single inactive\")\n",
    "ax.scatter([], [], c='tab:blue', alpha=0.6, s=9, label=\"single active\")\n",
    "\n",
    "plt.xlabel(\"Maximum allowed number of targets\")\n",
    "plt.ylabel(\"Weighted relative\\ndesign quality (%)\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim([0, 105])\n",
    "plt.tight_layout()\n",
    "for format in [\"png\", \"svg\"]:\n",
    "    plt.savefig(os.path.join(plot_folder, f\"quality_targets_used.{format}\"), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a plot of the mean targets used and unique miRNAs used\n",
    "plt.clf()\n",
    "fig, ax = plt.subplots(figsize=(2, 1.6))\n",
    "mean_by_target = all_dfs_target.groupby(\"target_number\")[\"unique_mirnas\"].mean()\n",
    "std_by_target = all_dfs_target.groupby(\"target_number\")[\"unique_mirnas\"].std()\n",
    "plt.errorbar(x=target_numbers, y=mean_by_target, yerr=std_by_target, label=\"single inactive\",\n",
    "                fmt=\"o-\", color=\"tab:red\", capsize=3, markersize=5)\n",
    "mean_by_target = all_dfs_active.groupby(\"target_number\")[\"unique_mirnas\"].mean()\n",
    "std_by_target = all_dfs_active.groupby(\"target_number\")[\"unique_mirnas\"].std()\n",
    "plt.errorbar(x=target_numbers, y=mean_by_target, yerr=std_by_target, label=\"single active\",\n",
    "                fmt=\"o-\", color=\"tab:blue\", capsize=3, markersize=5)\n",
    "plt.xlabel(\"Maximum allowed number of targets\")\n",
    "plt.ylabel(\"Unique targets\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.yticks(np.arange(1, 9, 1))\n",
    "plt.ylim([0.5, 8.5])\n",
    "plt.tight_layout()\n",
    "for format in [\"png\", \"svg\"]:\n",
    "    plt.savefig(os.path.join(plot_folder, f\"unique_targets_used.{format}\"), dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
